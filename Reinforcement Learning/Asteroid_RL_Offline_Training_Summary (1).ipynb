{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rybc-_hPmfw"
      },
      "source": [
        "# **Load the Data and Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXLi0ehpigHx",
        "outputId": "41cac51a-3123-431b-bdd5-3bff6f99f8ce"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB2dPK4s7BOk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils import data\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import math\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "import gc\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFRibrGz5Zcr"
      },
      "outputs": [],
      "source": [
        "#data_path = \"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_0.npy\"\n",
        "data_path = \"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_0.npy\"\n",
        "data_RL_preset0 = np.load(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Ok0wjI-jq4L-",
        "outputId": "b9dd572e-23f8-4822-8cdc-9b56878bf830"
      },
      "outputs": [],
      "source": [
        "#data_path1 = \"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_1.npy\"\n",
        "\n",
        "data_path_list = []\n",
        "data_path_list.append(\"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_1.npy\")\n",
        "data_path_list.append(\"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_2.npy\")\n",
        "#data_path_list.append(\"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_filtered_3.npy\")\n",
        "\n",
        "\n",
        "data_RL_preset_temp = np.load(data_path_list[0])\n",
        "new_len = int(1*(data_RL_preset_temp[0, 0]//800))*800\n",
        "data_RL_preset0[0, 0] = data_RL_preset0[0, 0] + new_len\n",
        "data_RL_preset0 = np.concatenate((data_RL_preset0, data_RL_preset_temp[1:new_len+1, :]), axis=0)\n",
        "del data_RL_preset_temp\n",
        "gc.collect()\n",
        "\n",
        "data_RL_preset_temp = np.load(data_path_list[1])\n",
        "new_len = int(1*(data_RL_preset_temp[0, 0]//800))*800\n",
        "data_RL_preset0[0, 0] = data_RL_preset0[0, 0] + new_len\n",
        "data_RL_preset0 = np.concatenate((data_RL_preset0, data_RL_preset_temp[1:new_len+1, :]), axis=0)\n",
        "del data_RL_preset_temp\n",
        "gc.collect()\n",
        "\n",
        "\"\"\"\n",
        "data_RL_preset_temp = np.load(data_path_list[2])\n",
        "new_len = int(0.5*(data_RL_preset_temp[0, 0]//800))*800\n",
        "data_RL_preset0[0, 0] = data_RL_preset0[0, 0] + new_len\n",
        "data_RL_preset0 = np.concatenate((data_RL_preset0, data_RL_preset_temp[1:new_len+1, :]), axis=0)\n",
        "del data_RL_preset_temp\n",
        "gc.collect()\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "for path in data_path_list:\n",
        "  data_RL_preset_temp = np.load(path)\n",
        "  data_RL_preset0[0, 0] = data_RL_preset0[0, 0] + data_RL_preset_temp[0, 0] - 1\n",
        "  data_RL_preset0 = np.concatenate((data_RL_preset0, data_RL_preset_temp[1:, :]), axis=0)\n",
        "  del data_RL_preset_temp\n",
        "  gc.collect()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S920S4KYs2Ig"
      },
      "outputs": [],
      "source": [
        "#data_path2 = \"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_2.npy\"\n",
        "data_path2 = \"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_filtered_4.npy\"\n",
        "data_RL_preset2 = np.load(data_path2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aRTxl7UfYFY",
        "outputId": "492ef833-b721-4501-9040-dd2937d0cb5f"
      },
      "outputs": [],
      "source": [
        "print(data_RL_preset0[0, 0])\n",
        "print(data_RL_preset0[0, 1])\n",
        "print(data_RL_preset0[0, 2])\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CE_eJhhcVoqh"
      },
      "outputs": [],
      "source": [
        "class RewardMapModifier():\n",
        "    def __init__(self, extends=(0, 1), blur_coef=(5, 3)):\n",
        "        self.extends = extends\n",
        "        self.blur_coef = blur_coef\n",
        "\n",
        "    def extend_hori(self, reward_map, action_maps):\n",
        "        left_reward = reward_map[..., :, -int(reward_map.shape[-2]*self.extends[1]/2):, :]\n",
        "        right_reward = reward_map[..., :, :int(reward_map.shape[-2]*self.extends[1]/2), :]\n",
        "\n",
        "        if action_maps is not None:\n",
        "            left_actions = action_maps[..., :, -int(action_maps.shape[-2]*self.extends[1]/2):, :].copy()\n",
        "            right_actions = action_maps[..., :, :int(action_maps.shape[-2]*self.extends[1]/2), :].copy()\n",
        "            left_actions[..., :, :, 0] = left_actions[..., :, :, 0] - 1\n",
        "            right_actions[..., :, :, 0] = right_actions[..., :, :, 0] + 1\n",
        "\n",
        "        if self.extends[1] != 0:\n",
        "            extended_reward = np.concatenate((left_reward, reward_map, right_reward), axis=-2)\n",
        "            extended_actions = np.concatenate((left_actions, action_maps, right_actions), axis=-2) if action_maps is not None else action_maps\n",
        "        else:\n",
        "            extended_reward = reward_map\n",
        "            extended_actions = action_maps\n",
        "\n",
        "        return extended_reward, extended_actions\n",
        "\n",
        "    def extend_vert(self, reward_map, action_maps):\n",
        "        top_reward = np.roll(reward_map[..., :int(reward_map.shape[-3]*self.extends[0]/2), :, :], 20, axis=-2)\n",
        "        bottom_reward = np.roll(reward_map[..., -int(reward_map.shape[-3]*self.extends[0]/2):, :, :], 20, axis=-2)\n",
        "        top_reward = np.flip(top_reward, axis=-3)\n",
        "        bottom_reward = np.flip(bottom_reward, axis=-3)\n",
        "\n",
        "        if action_maps is not None:\n",
        "            top_actions = np.flip(action_maps[..., :int(action_maps.shape[-3]*self.extends[0]/2), :, :].copy(), -3)\n",
        "            bottom_actions = np.flip(action_maps[..., -int(action_maps.shape[-3]*self.extends[0]/2):, :, :].copy(), -3)\n",
        "            top_actions[..., :, :, 1] = 2*0 - top_actions[..., :, :, 1]\n",
        "            bottom_actions[..., :, :, 1] = 2*1 - bottom_actions[..., :, :, 1]\n",
        "\n",
        "        if self.extends[0] != 0:\n",
        "            extended_reward = np.concatenate((top_reward, reward_map, bottom_reward), axis=-3)\n",
        "            extended_actions = np.concatenate((top_actions, action_maps, bottom_actions), axis=-3) if action_maps is not None else action_maps\n",
        "        else:\n",
        "            extended_reward = reward_map\n",
        "            extended_actions = action_maps\n",
        "\n",
        "        return extended_reward, extended_actions\n",
        "\n",
        "    def blur(self, reward_map):\n",
        "        #reward_map = 2.5 * np.tan( reward_map * (np.pi/2) / 6 )\\n\",\n",
        "        if len(reward_map.shape) == 3:\n",
        "            reward_map[:, :, 0] = cv2.GaussianBlur(reward_map[:, :, 0], (self.blur_coef[0], self.blur_coef[0]), self.blur_coef[1])\n",
        "        elif len(reward_map.shape) == 4:\n",
        "            for i in range(reward_map.shape[0]):\n",
        "                reward_map[i, :, :, 0] = cv2.GaussianBlur(reward_map[i, :, :, 0], (self.blur_coef[0], self.blur_coef[0]), self.blur_coef[1])\n",
        "                #max_val = np.max(np.abs(reward_map[i, :, :, 0]))\n",
        "                #reward_map[i, :, :, 0] = 6 * (2/np.pi) * np.arctan(reward_map[i, :, :, 0]/2) / ((2/np.pi) * np.arctan(max_val/2))\n",
        "        reward_map = 6 * (2/np.pi) * np.arctan(reward_map/8)\n",
        "        #reward_map = 6 * 2*(1/(1+np.exp(-reward_map/7)) - 0.5)\n",
        "        #reward_map = 6 * (2/np.pi) * np.arctan(reward_map/2)\n",
        "        return reward_map\n",
        "\n",
        "    def operation(self, reward_map, action_maps, order=['extend_hori', 'extend_vert', 'blur']):\n",
        "        result_reward = reward_map\n",
        "        result_action = action_maps\n",
        "        for op in order:\n",
        "            if op == 'extend_hori':\n",
        "                result_reward, result_action = self.extend_hori(result_reward, result_action)\n",
        "            elif op == 'extend_vert':\n",
        "                result_reward, result_action = self.extend_vert(result_reward, result_action)\n",
        "            elif op == 'blur':\n",
        "                result_reward = self.blur(result_reward)\n",
        "            else:\n",
        "                raise NotImplementedError()\n",
        "        return result_reward, result_action\n",
        "\n",
        "    def ext_N_set(self, N_set):\n",
        "        return (N_set[0]+2*int(N_set[0]*self.extends[1]/2), N_set[1]+2*int(N_set[1]*self.extends[0]/2))\n",
        "\n",
        "class EarlyStopping():\n",
        "    def __init__(self, patience, delta, mode='min'):\n",
        "        \"\"\"\n",
        "        patience : max number of waiting\n",
        "        delta : min boundary of \"change\"\n",
        "        mode :\n",
        "        verbose :\n",
        "        \"\"\"\n",
        "\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.mode = mode\n",
        "        self.best_score = np.inf if mode == 'min' else 0\n",
        "        self.count = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, score):\n",
        "        if self.mode == 'min':\n",
        "            if (self.best_score - score) < self.delta:\n",
        "                self.count += 1\n",
        "            else:\n",
        "                self.best_score = score\n",
        "                self.count = 0\n",
        "        elif self.mode == 'max':\n",
        "            if (score - self.best_score) < self.delta:\n",
        "                self.count += 1\n",
        "            else:\n",
        "                self.best_score = score\n",
        "                self.count = 0\n",
        "\n",
        "        if self.count >= self.patience:\n",
        "            self.early_stop = True\n",
        "\n",
        "def data_split(dataset, train_ratio=0.7, shuffle=True, copy=False):\n",
        "    if shuffle:\n",
        "        idx = np.arange(0, dataset.shape[0])\n",
        "        np.random.shuffle(idx)\n",
        "        dataset = dataset[idx]\n",
        "\n",
        "    trainset = dataset[:int(train_ratio*dataset.shape[0])]\n",
        "    testset = dataset[int(train_ratio*dataset.shape[0]):]\n",
        "    if copy:\n",
        "        trainset = trainset.copy()\n",
        "        testset = testset.copy()\n",
        "\n",
        "    return trainset, testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dROAVqHfPwr-"
      },
      "source": [
        "# **Training with Regression Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rELvafVHp3v"
      },
      "outputs": [],
      "source": [
        "class QValueNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=512, activation=nn.ReLU, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.activation = activation\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, self.hidden_dim),\n",
        "            activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            #------------------------------\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            #nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            #activation(),\n",
        "            #nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim//4),\n",
        "            activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(self.hidden_dim//4, self.hidden_dim//8),\n",
        "            activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(self.hidden_dim//8, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.model(X)\n",
        "\n",
        "\n",
        "class QValueNet_CNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=512, activation=nn.ReLU, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.activation = activation\n",
        "\n",
        "        # R_arr encoders (input: [B, C, 40, 20])\n",
        "        self.r_arr_encoder1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, (9, 5)),  # 1 channel / assumed input is already done padding=1 #(1, 16, 3)\n",
        "            self.activation(),\n",
        "            nn.MaxPool2d(2)  # -> 20×10\n",
        "        )\n",
        "\n",
        "        self.r_arr_encoder2 = nn.Sequential(\n",
        "            nn.Conv2d(8, 16, (5, 3)),  # assumed input is already done padding=1 #(16, 32, 3)\n",
        "            self.activation(),\n",
        "            nn.Flatten(),     # -> 16×20×10 = 3200  # -> 32×20×10 = 6400\n",
        "            nn.Linear(3200, 1024)\n",
        "        )\n",
        "\n",
        "        # Info encoder (input: [B, 1, 6])\n",
        "        self.info_encoder = nn.Sequential(\n",
        "            nn.Linear(6, 32),\n",
        "            self.activation(),\n",
        "            nn.Linear(32, 64)\n",
        "        )\n",
        "\n",
        "        # RL encoder (input: [B, 1, 4])\n",
        "        self.rl_encoder = nn.Sequential(\n",
        "            nn.Linear(4, 32),\n",
        "            self.activation(),\n",
        "            nn.Linear(32, 64)\n",
        "        )\n",
        "\n",
        "        # Lightcurves encoder (input: [B, 1, 100])\n",
        "        self.lc_encoder1 = nn.Sequential(\n",
        "            nn.Conv1d(1, 16, kernel_size=15),\n",
        "            self.activation(),\n",
        "            nn.MaxPool1d(2),   # → 50\n",
        "        )\n",
        "\n",
        "        self.lc_encoder2 = nn.Sequential(\n",
        "            nn.Conv1d(16, 32, kernel_size=9),\n",
        "            self.activation(),\n",
        "            nn.Flatten(),      # → 32×50\n",
        "            nn.Linear(32*50, 256)\n",
        "        )\n",
        "\n",
        "        # Fusion & Head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(1024 + 256 + 64 + 64, 1024),\n",
        "            self.activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(1024, 1024),\n",
        "            self.activation(),\n",
        "            nn.Dropout(dropout), #//// 새로 추가 0926_2\n",
        "\n",
        "            #nn.Linear(1024, 1024),\n",
        "            #self.activation(),\n",
        "            #nn.Dropout(dropout), #//// 새로 추가 0926_2 # 삭제 0927_1\n",
        "\n",
        "            nn.Linear(1024, 256),\n",
        "            self.activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(256, 1)  # e.g., class count or regression value\n",
        "        )\n",
        "\n",
        "    def r_padding(self, x, pad=(1, 1)):\n",
        "        N, C, H, W = x.shape\n",
        "        pad_H = pad[0]\n",
        "        pad_W = pad[1]\n",
        "\n",
        "        out = torch.full((N, C, H + 2*pad_H, W + 2*pad_W), fill_value=0.0, dtype=x.dtype, device=x.device)\n",
        "        out[:, :, pad_H:pad_H+H, pad_W:pad_W+W] = x\n",
        "        out[:, :, :, :pad_W] = torch.roll(torch.flip(out[:, :, :, pad_W:pad_W+pad_W], (-2,)), 20, -1)\n",
        "        out[:, :, :, -pad_W:] = torch.roll(torch.flip(out[:, :, :, -pad_W-pad_W:-pad_W], (-2,)), 20, -1)\n",
        "        out[:, :, :pad_H, pad_W:pad_W+W] = x[:, :, -pad_H:, :]\n",
        "        out[:, :, -pad_H:, pad_W:pad_W+W] = x[:, :, :pad_H, :]\n",
        "        return out\n",
        "\n",
        "    def lc_padding(self, x, pad=1):\n",
        "        N, C, W = x.shape\n",
        "\n",
        "        out = torch.full((N, C, W + 2*pad), fill_value=0.0, dtype=x.dtype, device=x.device)\n",
        "        out[:, :, pad:pad+W] = x\n",
        "        out[:, :, :pad] = x[:, :, -pad:]\n",
        "        out[:, :, -pad:] = x[:, :, :pad]\n",
        "        return out\n",
        "\n",
        "    def shifter(self, img, dx=0, dy=0):\n",
        "        PI = 3.14159265358979\n",
        "        img_F = torch.fft.fft2(img)\n",
        "        N, M = img.shape\n",
        "        ky = torch.fft.fftfreq(N)[:, None].to(device)\n",
        "        kx = torch.fft.fftfreq(M)[None, :].to(device)\n",
        "        phase = torch.exp(-2j*PI*(kx*dx + ky*dy))\n",
        "        new_img = torch.fft.ifft2(img_F*phase)\n",
        "        return new_img.real\n",
        "\n",
        "    def forward(self, X):\n",
        "        r_arr = X[..., :800].reshape((X.shape[0], 1, 40, 20))\n",
        "        lc_arr = X[..., 800:900].reshape((X.shape[0], 1, 100))\n",
        "        lc_info = X[..., 900:906]\n",
        "        rl_info = X[..., 906:]\n",
        "\n",
        "        r_arr_feat = torch.transpose(r_arr, -2, -1)\n",
        "        r_arr_feat = self.r_padding(r_arr_feat, pad=(4, 2))\n",
        "        r_arr_feat = self.r_arr_encoder1(r_arr_feat)\n",
        "        r_arr_feat = self.r_padding(r_arr_feat, pad=(2, 1))\n",
        "        r_arr_feat = self.r_arr_encoder2(r_arr_feat)\n",
        "\n",
        "        lc_feat = self.lc_padding(lc_arr, pad=7)\n",
        "        lc_feat = self.lc_encoder1(lc_feat)\n",
        "        lc_feat = self.lc_padding(lc_feat, pad=4)\n",
        "        lc_feat = self.lc_encoder2(lc_feat)\n",
        "\n",
        "        info_feat = self.info_encoder(lc_info)\n",
        "        info_feat = torch.squeeze(info_feat, dim=1)\n",
        "\n",
        "        rl_feat = self.rl_encoder(rl_info)\n",
        "        rl_feat = torch.squeeze(rl_feat, dim=1)\n",
        "\n",
        "        fusion_feat = torch.cat((r_arr_feat, lc_feat, info_feat, rl_feat), dim=1)\n",
        "        out = self.head(fusion_feat)\n",
        "        #shift_out = self.shift_head(fusion_feat)\n",
        "\n",
        "        #self.x_shift = torch.unsqueeze(shift_out[..., 0], dim=1)\n",
        "        #self.y_shift = torch.unsqueeze(shift_out[..., 1], dim=1)\n",
        "\n",
        "        #out = self.shifter(out, dx=20*self.x_shift, dy=10*self.y_shift)\n",
        "\n",
        "        PI = 3.14159265358979\n",
        "        out = 6 * 2 / PI * torch.atan(out/0.8) #out/0.8\n",
        "        #out = 7 * 2 / PI * torch.atan(1.5 * out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self, relative, percent):\n",
        "      super().__init__()\n",
        "      self.relative = relative\n",
        "      self.percent = percent\n",
        "\n",
        "    def forward(self, input, target):\n",
        "      torch_MSE = nn.MSELoss()\n",
        "      if self.relative:\n",
        "          loss = torch_MSE(input/(target+1e-6), target/(target+1e-6))\n",
        "          loss = torch.sqrt(loss + 1e-6)\n",
        "      else:\n",
        "          loss = torch.sqrt(torch_MSE(input, target))\n",
        "          #weight = 0.5 + 0.5*torch.abs(target)\n",
        "          #loss = torch.sum(weight*(input-target)**2)/torch.sum(weight)\n",
        "          #loss = torch.sqrt(loss + 1e-6)\n",
        "      if self.percent:\n",
        "          loss = 100 * loss\n",
        "      return loss\n",
        "\n",
        "class CustomLoss1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        input_reshaped = input.reshape(-1, 20, 40)\n",
        "        target_reshaped = target.reshape(-1, 20, 40)\n",
        "\n",
        "        torch_MSE = nn.MSELoss()\n",
        "        input_prop = self.processer(input_reshaped)\n",
        "        target_prop = self.processer(target_reshaped)\n",
        "\n",
        "        #input_prop_pos = torch.where(input_prop > 0, input_prop, 0)\n",
        "        #input_prop_neg = torch.where(input_prop < 0, input_prop, 0)\n",
        "        #input_prop_final = input_prop_pos*torch.max(target_prop)/(torch.max(input_prop_pos)+1e-6) + input_prop_neg*torch.min(target_prop)/(torch.min(input_prop_neg)+1e-6)\n",
        "        #target_prop_pos = torch.where(target_prop > 0, target_prop, 0)\n",
        "        #target_prop_neg = torch.where(target_prop < 0, target_prop, 0)\n",
        "        #target_prop_final = target_prop_pos*torch.max(input_prop)/(torch.max(target_prop_pos)+1e-6) + target_prop_neg*torch.min(input_prop)/(torch.min(target_prop_neg)+1e-6)\n",
        "\n",
        "        loss = torch_MSE(input_prop, target_prop)\n",
        "        return 1e+6 * loss\n",
        "\n",
        "    def processer(self, reward_map):\n",
        "        hori_prop, vert_prop = 3, 3\n",
        "        reward_map_pos = torch.where(reward_map > 0, reward_map, 0)\n",
        "        reward_map_neg = torch.where(reward_map < 0, reward_map, 0)\n",
        "\n",
        "        exp = 2\n",
        "        div = hori_prop + vert_prop - 0.5\n",
        "        reward_map_prop = reward_map_pos**exp\n",
        "        for i in range(1, hori_prop+1):\n",
        "            reward_map_prop[..., :, :-i] = reward_map_prop[..., :, :-i] + reward_map_pos[..., :, i:]**exp\n",
        "            reward_map_prop[..., :,  i:] = reward_map_prop[..., :,  i:] + reward_map_pos[..., :, :-i]**exp\n",
        "        for j in range(1, vert_prop+1):\n",
        "            reward_map_prop[..., :-j, :] = reward_map_prop[..., :-j, :] + reward_map_pos[...,  j:, :]**exp\n",
        "            reward_map_prop[...,  j:, :] = reward_map_prop[...,  j:, :] + reward_map_pos[..., :-j, :]**exp\n",
        "        reward_map_prop = (reward_map_prop / div)**(1/exp)\n",
        "        reward_map_prop = reward_map_prop + reward_map_neg\n",
        "\n",
        "        return reward_map_prop\n",
        "\n",
        "class CustomLoss2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.epoch = 0\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        input_reshaped = torch.transpose(input.reshape(-1, 40, 20), 1, 2)\n",
        "        target_reshaped = torch.transpose(target.reshape(-1, 40, 20), 1, 2)\n",
        "\n",
        "        torch_MSE = nn.MSELoss()\n",
        "        input_prop = self.processer(input_reshaped)\n",
        "        target_prop = self.processer(target_reshaped)\n",
        "\n",
        "        eps = 0.3\n",
        "        input_prop_pos = torch.where(input_prop > 0, input_prop, 0)\n",
        "        input_prop_neg = torch.where(input_prop < 0, input_prop, 0)\n",
        "        input_prop_final = input_prop_pos*torch.amax(target_prop, dim=(1, 2))[:, None, None]/(torch.amax(input_prop_pos, dim=(1, 2))[:, None, None]+eps)\n",
        "        input_prop_final = input_prop_final + input_prop_neg*torch.amin(target_prop, dim=(1, 2))[:, None, None]/(torch.amin(input_prop_neg, dim=(1, 2))[:, None, None]+eps)\n",
        "        #target_prop_pos = torch.where(target_prop > 0, target_prop, 0)\n",
        "        #target_prop_neg = torch.where(target_prop < 0, target_prop, 0)\n",
        "        #target_prop_final = target_prop_pos*torch.max(input_prop)/(torch.max(target_prop_pos)+1e-6) + target_prop_neg*torch.min(input_prop)/(torch.min(target_prop_neg)+1e-6)\n",
        "\n",
        "        loss = torch_MSE(input_prop, target_prop)\n",
        "        return loss\n",
        "\n",
        "    def processer(self, reward_map):\n",
        "        hori_prop, vert_prop = 3, 3\n",
        "        reward_map_pos = torch.where(reward_map > 0, reward_map, 0)\n",
        "        reward_map_neg = torch.where(reward_map < 0, reward_map, 0)\n",
        "\n",
        "        exp = 2\n",
        "        div = hori_prop + vert_prop - 0.5\n",
        "        reward_map_prop = reward_map_pos**exp\n",
        "        for i in range(1, hori_prop+1):\n",
        "            reward_map_prop[..., :, :-i] = reward_map_prop[..., :, :-i] + reward_map_pos[..., :, i:]**exp\n",
        "            reward_map_prop[..., :,  i:] = reward_map_prop[..., :,  i:] + reward_map_pos[..., :, :-i]**exp\n",
        "        for j in range(1, vert_prop+1):\n",
        "            reward_map_prop[..., :-j, :] = reward_map_prop[..., :-j, :] + reward_map_pos[...,  j:, :]**exp\n",
        "            reward_map_prop[...,  j:, :] = reward_map_prop[...,  j:, :] + reward_map_pos[..., :-j, :]**exp\n",
        "        reward_map_prop = (reward_map_prop / div)**(1/exp)\n",
        "        reward_map_prop = reward_map_prop + reward_map_neg\n",
        "\n",
        "        return reward_map_prop\n",
        "\n",
        "    def setepoch(self, epoch):\n",
        "        self.epoch = epoch\n",
        "\n",
        "class CustomLoss3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.epoch = 0\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        PI = 3.141592\n",
        "        input_reshaped = torch.transpose(input.reshape(-1, 40, 20), 1, 2)\n",
        "        target_reshaped = torch.transpose(target.reshape(-1, 40, 20), 1, 2)\n",
        "        input_reshaped = 3*(2/PI)*torch.arctan(input_reshaped/2)\n",
        "        taget_reshaped = 3*(2/PI)*torch.arctan(target_reshaped/2)\n",
        "\n",
        "        torch_MSE = nn.MSELoss()\n",
        "        input_prop = self.processer(input_reshaped)\n",
        "        target_prop = self.processer(target_reshaped)\n",
        "\n",
        "        beta = 0.3\n",
        "        input_prop_pos = torch.where(input_prop > 0, input_prop, 0)\n",
        "        input_prop_neg = torch.where(input_prop < 0, input_prop, 0)\n",
        "        input_prop_final = input_prop_pos*3/(torch.amax(input_prop_pos, dim=(1, 2))[:, None, None]+beta)\n",
        "        input_prop_final = input_prop_final + 3/(-torch.amin(input_prop_neg, dim=(1, 2))[:, None, None]+beta)\n",
        "        #input_prop_final = input_prop_pos*torch.amax(target_prop, dim=(1, 2))[:, None, None]/(torch.amax(input_prop_pos, dim=(1, 2))[:, None, None]+beta)\n",
        "        #input_prop_final = input_prop_final + input_prop_neg*torch.amin(target_prop, dim=(1, 2))[:, None, None]/(-torch.amin(input_prop_neg, dim=(1, 2))[:, None, None]+beta)\n",
        "        #target_prop_pos = torch.where(target_prop > 0, target_prop, 0)\n",
        "        #target_prop_neg = torch.where(target_prop < 0, target_prop, 0)\n",
        "        #target_prop_final = target_prop_pos*torch.max(input_prop)/(torch.max(target_prop_pos)+1e-6) + target_prop_neg*torch.min(input_prop)/(torch.min(target_prop_neg)+1e-6)\n",
        "\n",
        "        loss = torch_MSE(input_prop, target_prop)\n",
        "        return loss\n",
        "\n",
        "    def processer(self, reward_map):\n",
        "        hori_prop, vert_prop = 1, 1\n",
        "        reward_map_pos = torch.where(reward_map > 0, reward_map, 0)\n",
        "        reward_map_neg = torch.where(reward_map < 0, reward_map, 0)\n",
        "\n",
        "        exp = 1.8\n",
        "        div = hori_prop + vert_prop - 0.5\n",
        "        reward_map_prop = reward_map_pos**exp\n",
        "        for i in range(1, hori_prop+1):\n",
        "            reward_map_prop[..., :, :-i] = reward_map_prop[..., :, :-i] + reward_map_pos[..., :, i:]**exp\n",
        "            reward_map_prop[..., :,  i:] = reward_map_prop[..., :,  i:] + reward_map_pos[..., :, :-i]**exp\n",
        "        for j in range(1, vert_prop+1):\n",
        "            reward_map_prop[..., :-j, :] = reward_map_prop[..., :-j, :] + reward_map_pos[...,  j:, :]**exp\n",
        "            reward_map_prop[...,  j:, :] = reward_map_prop[...,  j:, :] + reward_map_pos[..., :-j, :]**exp\n",
        "        reward_map_prop = (reward_map_prop / div)**(1/exp)\n",
        "        reward_map_prop = reward_map_prop + reward_map_neg\n",
        "\n",
        "        return reward_map_prop\n",
        "\n",
        "    def setepoch(self, epoch):\n",
        "        self.epoch = epoch\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer, train_loss, es:EarlyStopping):\n",
        "    epoch_loss = 0\n",
        "    n_train = 0\n",
        "\n",
        "    model.train()\n",
        "    #with torch.autograd.detect_anomaly(True):\n",
        "    for X_train, y_train in dataloader:\n",
        "        X_train = X_train.to(device)\n",
        "        y_train = y_train.to(device)\n",
        "        pred = model(X_train)\n",
        "\n",
        "        #non_extended = torch.logical_and((X_train[:, -4] >= 0), (X_train[:, -4] < 1))\n",
        "        #non_extended = torch.logical_and(non_extended, (X_train[:, -3] >= 0))\n",
        "        #non_extended = torch.logical_and(non_extended, (X_train[:, -3] < 1))\n",
        "        #loss = loss_fn(pred[non_extended], y_train[non_extended])\n",
        "\n",
        "        loss = loss_fn(pred, y_train)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()*X_train.size(0)\n",
        "        n_train += X_train.size(0)\n",
        "\n",
        "    epoch_loss /= n_train\n",
        "    train_loss.append(epoch_loss)\n",
        "\n",
        "    es(epoch_loss)\n",
        "    #print(\"train_loss : {:9.4g}\".format(epoch_loss), end=' ')\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn, test_loss, indv_losses_temp, epoch):\n",
        "    epoch_loss = 0\n",
        "    n_test = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X_test, y_test in dataloader:\n",
        "            X_test = X_test.to(device)\n",
        "            y_test = y_test.to(device)\n",
        "            pred = model(X_test)\n",
        "\n",
        "            #non_extended = torch.logical_and((X_test[:, -4] >= 0), (X_test[:, -4] < 1))\n",
        "            #non_extended = torch.logical_and(non_extended, (X_test[:, -3] >= 0))\n",
        "            #non_extended = torch.logical_and(non_extended, (X_test[:, -3] < 1))\n",
        "            #epoch_loss += loss_fn(pred[non_extended], y_test[non_extended]).item()*X_test.size(0)\n",
        "\n",
        "            #epoch_loss += loss_fn(pred, y_test).item()*X_test.size(0)\n",
        "            each_loss = loss_fn(torch.transpose(pred.reshape(40, 20), 0, 1), torch.transpose(y_test.reshape(40, 20), 0, 1)).item()*X_test.size(0)\n",
        "            epoch_loss += each_loss\n",
        "            n_test += X_test.size(0)\n",
        "            indv_losses_temp.append(each_loss/800)\n",
        "\n",
        "    epoch_loss /= n_test\n",
        "    test_loss.append(epoch_loss)\n",
        "\n",
        "    print(\"train_loss : {:9.4g}\".format(train_loss[-1]), end=' ')\n",
        "    print(\"| test_loss : {:9.4g}\".format(epoch_loss), end=' ')\n",
        "    print(\"\\n\", end=' ')\n",
        "\n",
        "# Data Processing : scaling data\n",
        "param = [6, 2] #[6, 2.5]\n",
        "def scale_reward(data):\n",
        "    if data_RL_preset0[0, 2] == 1: # already scaled\n",
        "        return data\n",
        "\n",
        "    data_RL_preset0[0, 2] = 1\n",
        "    scaled_data = np.zeros_like(data)\n",
        "\n",
        "    scaled_data = param[0]*(2/np.pi)*np.arctan(data/param[1])\n",
        "\n",
        "    return scaled_data\n",
        "\n",
        "def test_img_show(i_img, loss_fn):\n",
        "    fig = plt.figure(figsize=(16, 8), dpi=300)\n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "    ax2 = fig.add_subplot(1, 2, 2)\n",
        "\n",
        "    extent = ( (N_set[0]-ext_N_set[0])/2, (N_set[0]+ext_N_set[0])/2, (N_set[1]+ext_N_set[1])/2, (N_set[1]-ext_N_set[1])/2 )\n",
        "    if i_img == 0 or True:\n",
        "        ax1.clear()\n",
        "        im1 = ax1.imshow(test_img_list[i_img], vmin=-param[0], vmax=param[0], extent=extent)\n",
        "        #im1 = ax1.imshow(test_img_list[i_img], extent=extent)\n",
        "        ax1.set_title(\"TEST_IMAGE_\"+str(i_img))\n",
        "        plt.colorbar(im1, ax=ax1, fraction=0.026, pad=0.04)\n",
        "        ax1.plot([0, N_set[0]],        [0, 0],               color='red', linestyle='solid')\n",
        "        ax1.plot([0, N_set[0]],        [N_set[1], N_set[1]], color='red', linestyle='solid')\n",
        "        ax1.plot([0, 0],               [0, N_set[1]],        color='red', linestyle='solid')\n",
        "        ax1.plot([N_set[0], N_set[0]], [0, N_set[1]],        color='red', linestyle='solid')\n",
        "\n",
        "    reward_map_temp = np.zeros((resol*N_set[0], resol*N_set[1]))\n",
        "    loss_test_img_temp = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(N_set[0]*N_set[1]*resol*resol):\n",
        "            i = idx//int(resol*N_set[1])\n",
        "            j = idx%int(resol*N_set[1])\n",
        "            phi_action = (i/(resol*N_set[0]))%1\n",
        "            theta_action = (j/(resol*N_set[1]))%1\n",
        "\n",
        "            state = test_img_data[i_img*resol*N_set[0]*N_set[1], :906]\n",
        "            actions = np.array([phi_action, theta_action, 0.1, 0.1])\n",
        "\n",
        "            input = torch.tensor(np.concatenate((state, actions))).float().to(device)\n",
        "            input = torch.unsqueeze(input, 0)\n",
        "            reward = model(input)\n",
        "            reward_map_temp[i, j] = reward\n",
        "        loss_test_img_temp += loss_fn(torch.tensor(reward_map_temp.T).cpu(), torch.tensor(test_img_list[i_img][:, :, 0])).item() # only valid if no extend\n",
        "    ax2.clear()\n",
        "    #im2 = ax2.imshow(reward_map_temp.T)#, vmin=-param[0], vmax=param[0])\n",
        "    im2 = ax2.imshow(reward_map_temp.T, vmin=-np.max(np.abs(reward_map_temp)), vmax=np.max(np.abs(reward_map_temp)))\n",
        "    ax2.set_title(\"MODEL_OUTPUT_\"+str(i_img)+\"(Loss=\"+str(int(1000*loss_test_img_temp)/1000)+\")\")\n",
        "    plt.colorbar(im2, ax=ax2, fraction=0.026, pad=0.04)\n",
        "\n",
        "    plt.show()\n",
        "    print(\"Test Img \"+str(i_img)+\" Loss = \"+str(int(1000*loss_test_img_temp)/1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1yGwp6IK5zo"
      },
      "source": [
        "### Data Preprocessing with Small Size Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTXZcDLp35Rv"
      },
      "outputs": [],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, x_tensor, y_tensor):\n",
        "        super(Dataset, self).__init__()\n",
        "\n",
        "        if not torch.is_tensor(x_tensor):\n",
        "            self.x = torch.tensor(x_tensor).float()\n",
        "            self.y = torch.tensor(y_tensor).float()\n",
        "        else:\n",
        "            self.x = x_tensor.float()\n",
        "            self.y = y_tensor.float()\n",
        "\n",
        "    def __getitem__(self, index): return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self): return self.x.shape[0]\n",
        "\n",
        "class BlockShuffleSampler(data.Sampler):\n",
        "    def __init__(self, data_source, block_size: int, drop_last_block: bool = False, generator: torch.Generator | None = None):\n",
        "        self.data_source = data_source\n",
        "        self.N = len(data_source)\n",
        "        self.block_size = block_size\n",
        "        self.drop_last_block = drop_last_block\n",
        "        self.generator = generator\n",
        "\n",
        "        if self.block_size <= 0:\n",
        "            raise ValueError(\"block_size must be positive\")\n",
        "        if not drop_last_block and self.N % self.block_size != 0:\n",
        "            pass\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        if self.drop_last_block:\n",
        "            return (self.N // self.block_size) * self.block_size\n",
        "        return self.N\n",
        "\n",
        "    def __iter__(self):\n",
        "        N = self.__len__()\n",
        "        n_blocks = N // self.block_size + (0 if (self.drop_last_block or N % self.block_size == 0) else 1)\n",
        "\n",
        "        perm = torch.randperm(n_blocks, generator=self.generator).tolist() if n_blocks > 1 else list(range(n_blocks))\n",
        "\n",
        "        for b in perm:\n",
        "            start = b * self.block_size\n",
        "            end = min(start + self.block_size, N)\n",
        "            yield from range(start, end)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUxxexjYprep"
      },
      "source": [
        "#### Use data_RL_preset2 as Testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sc_eOe8pqfo",
        "outputId": "84b62715-cdbb-4417-eebc-a04bdca0cd1f"
      },
      "outputs": [],
      "source": [
        "# seed\n",
        "seed = 10#722\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 1024\n",
        "learning_rate = 6e-5\n",
        "max_epoch = 1000\n",
        "\n",
        "# other parameters\n",
        "N_set = (40, 20)\n",
        "resol = 1\n",
        "\n",
        "map_modifier = RewardMapModifier(extends=(0, 0), blur_coef=(3, 2)) #if you use CNN, do not use extend method\n",
        "chunk_size = 256\n",
        "chunk_set_size = chunk_size*N_set[0]*N_set[1]\n",
        "online_dataset_path = \"/content/gdrive/MyDrive/Asteroid RL dataset/online_dataset/\"\n",
        "\n",
        "\n",
        "data_len2 = int(data_RL_preset2[0, 0])\n",
        "test_img_num = 10\n",
        "test_img_idx_choice = np.random.randint(0, (data_len2-1)//800, test_img_num)\n",
        "dataset_img_idx = np.full(data_len2, False)\n",
        "for i in test_img_idx_choice:\n",
        "    dataset_img_idx[i*800+1:(i+1)*800+1] = True\n",
        "\n",
        "print(\"test_img_idx (in RL_preset_batch_2) :\", test_img_idx_choice)\n",
        "print(\"--------------------------------\")\n",
        "print(\"\")\n",
        "\n",
        "data_RL_preset = data_RL_preset0[1:, :]\n",
        "test_img_data = data_RL_preset2[dataset_img_idx, :].copy()\n",
        "del data_RL_preset2\n",
        "gc.collect()\n",
        "\n",
        "test_img_list = []\n",
        "for i in range(test_img_num):\n",
        "    test_img_list.append(test_img_data[i*resol*N_set[0]*N_set[1]:(i+1)*resol*N_set[0]*N_set[1], -1].reshape((N_set[0], N_set[1])).T)\n",
        "\n",
        "for i in range(len(test_img_list)):\n",
        "    test_img_list[i], _ = map_modifier.operation(np.expand_dims(test_img_list[i], axis=-1), None, order=['extend_vert', 'extend_hori', 'blur'])\n",
        "    #test_img_list[i] = test_img_list[i][:, :, 0]\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "#cut = N_set[0]*N_set[1]*2093 + 1 #1040\n",
        "#state_data = data_RL_preset[:cut, :-5]\n",
        "#action_data = data_RL_preset[:cut, -5:-1]\n",
        "#reward_data = data_RL_preset[:cut, -1:]\n",
        "state_data = data_RL_preset[:, :-5]\n",
        "action_data = data_RL_preset[:, -5:-1]\n",
        "reward_data = data_RL_preset[:, -1:]\n",
        "\n",
        "\n",
        "new_action_data = 0 * np.array([action_data[0, ...].copy()])\n",
        "new_reward_data = 0 * np.array([reward_data[0, ...].copy()])\n",
        "\n",
        "print(\"Data Shapes Before Map Modifying\")\n",
        "print(\"--------------------------------\")\n",
        "print(\"state_data  | \"+str(state_data.shape)+\", \"+str(int(1000*state_data.itemsize*state_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"action_data | \"+str(action_data.shape)+\"  , \"+str(int(1000*action_data.itemsize*action_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"reward_data | \"+str(reward_data.shape)+\"  , \"+str(int(1000*reward_data.itemsize*reward_data.size/(2**30))/1000)+\"GB\")\n",
        "\n",
        "print(\"\\n--------------------------------\")\n",
        "for i in range(math.ceil(state_data.shape[0]/chunk_set_size)):\n",
        "    if i != state_data.shape[0]//(chunk_size*N_set[0]*N_set[1]):\n",
        "        reward_map = reward_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
        "        action_maps = action_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
        "    else:\n",
        "        reward_map = reward_data[chunk_set_size*i:]\n",
        "        action_maps = action_data[chunk_set_size*i:]\n",
        "\n",
        "    print(\"Batch Shape : reward / action | \"+str(reward_map.shape)+\", \"+str(action_maps.shape)+\" --> \", end='')\n",
        "    reward_map = np.swapaxes(reward_map.reshape((-1, N_set[0], N_set[1], 1)), -2, -3)\n",
        "    action_maps = np.swapaxes(action_maps.reshape((-1, N_set[0], N_set[1], 4)), -2, -3)\n",
        "    reward_map, action_maps = map_modifier.operation(reward_map, action_maps, order=['extend_vert', 'extend_hori', 'blur'])\n",
        "    print(str(reward_map.shape)+\", \"+str(action_maps.shape))\n",
        "\n",
        "    extended_size = reward_map.shape[-2] * reward_map.shape[-3]\n",
        "    new_action_data = np.concatenate((new_action_data, action_maps.reshape(-1, 4)), axis=0)\n",
        "    new_reward_data = np.concatenate((new_reward_data, reward_map.reshape(-1, 1)), axis=0)\n",
        "print(\"--------------------------------\\n\")\n",
        "\n",
        "state_data = np.repeat(state_data[::N_set[0]*N_set[1]], repeats=extended_size, axis=0)\n",
        "action_data = np.delete(new_action_data, 0, axis=0)\n",
        "reward_data = np.delete(new_reward_data, 0, axis=0)\n",
        "\n",
        "del new_action_data, new_reward_data, reward_map, action_maps\n",
        "del data_RL_preset, data_RL_preset0\n",
        "gc.collect()\n",
        "\n",
        "print(\"Data Shapes After Map Mpdifying\")\n",
        "print(\"--------------------------------\")\n",
        "print(\"state_data  | \"+str(state_data.shape)+\", \"+str(int(1000*state_data.itemsize*state_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"action_data | \"+str(action_data.shape)+\"  , \"+str(int(1000*action_data.itemsize*action_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"reward_data | \"+str(reward_data.shape)+\"  , \"+str(int(1000*reward_data.itemsize*reward_data.size/(2**30))/1000)+\"GB\")\n",
        "\n",
        "ext_N_set = map_modifier.ext_N_set(N_set)\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Shifted Data Generation\n",
        "# ------------------------------\n",
        "'''\n",
        "shift_unit = 1 #1 is minimum unit --> most data generation (20 times)\n",
        "new_state_data = state_data.reshape(-1, 800, state_shape)\n",
        "new_action_data = action_data.reshape(-1, 800, 4)\n",
        "new_reward_data = np.swapaxes(reward_data.reshape(-1, 800, 40, 20), 2, 3)\n",
        "\n",
        "original_data_img_num = new_state_data.shape[0] + 0\n",
        "\n",
        "new_state_data = np.tile(new_state_data, (20//shift_unit, 1, 1))\n",
        "new_action_data = np.tile(new_action_data, (20//shift_unit, 1, 1))\n",
        "new_reward_data = np.tile(new_reward_data, (20//shift_unit, 1, 1, 1))\n",
        "for i in range(1, 20//shift_unit+1):\n",
        "    new_state_data[i*original_data_img_num:(i+1)*original_data_img_num, :, 800:900] = np.roll(new_state_data[i*original_data_img_num:(i+1)*original, :, 800:900], 5*shift_unit, axis=-1)\n",
        "    new_reward_data[i*original_data_img_num:(i+1)*original_data_img_num, :, :, :] = np.roll(ew_reward_data[i*original_data_img_num:(i+1)*original_data_img_num, :, :, :], 2*shift_unit, axis=-1)\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "total_data = np.concatenate((state_data, action_data, reward_data), axis=-1)\n",
        "state_shape = state_data.shape[1]\n",
        "del state_data, action_data, reward_data\n",
        "gc.collect()\n",
        "\n",
        "#train_data, test_data = data_split(total_data, train_ratio=0.85, shuffle=True, copy=True)\n",
        "train_data, test_data = data_split(total_data, train_ratio=1, shuffle=False, copy=True)\n",
        "del total_data, test_data\n",
        "gc.collect()\n",
        "\n",
        "train_data = train_data.reshape(-1, state_shape+4+1)\n",
        "\n",
        "train_state_data = train_data[:, :state_shape].copy()\n",
        "train_action_data = train_data[:, state_shape:state_shape+4].copy()\n",
        "train_reward_data = train_data[:, -1].reshape(-1, 1)\n",
        "del train_data\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t84_U22NqcvT",
        "outputId": "edc322ed-3c38-42c2-cabc-98562f9a42e7"
      },
      "outputs": [],
      "source": [
        "test_data = test_img_data.copy()\n",
        "print(\"\\n\"+(\"-\"*20))\n",
        "print(\"Test Data Shape : \"+str(test_data.shape))\n",
        "\n",
        "test_state_data = test_data[:, :state_shape].copy()\n",
        "test_action_data = test_data[:, state_shape:state_shape+4].copy()\n",
        "test_reward_data = np.swapaxes(test_data[:, -1].reshape(-1, 40, 20, 1), -2, -3)\n",
        "test_reward_data, _ = map_modifier.operation(test_reward_data, None, order=['extend_vert', 'extend_hori', 'blur'])\n",
        "test_reward_data = np.swapaxes(test_reward_data, -2, -3).reshape(-1, 1)\n",
        "\n",
        "del test_data\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGDD5gcApwCh"
      },
      "source": [
        "#### to Dataset class for pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xioy2hxbAXI",
        "outputId": "bcfd3712-f6f4-47fb-9bcf-5064184efa35"
      },
      "outputs": [],
      "source": [
        "c_batch = 800*1000 #converting batch size\n",
        "\n",
        "dataset_list = []\n",
        "c_batch_num = math.ceil(train_state_data.shape[0]/c_batch)\n",
        "for i in range(c_batch_num):\n",
        "    train_dataset_temp = Dataset(np.concatenate((train_state_data[:c_batch, :], train_action_data[:c_batch, :]), axis=1),\n",
        "                            train_reward_data[:c_batch, :])\n",
        "    if i == c_batch_num-1:\n",
        "        del train_state_data, train_action_data, train_reward_data\n",
        "    else:\n",
        "        train_state_data = train_state_data[c_batch:]\n",
        "        train_action_data = train_action_data[c_batch:]\n",
        "        train_reward_data = train_reward_data[c_batch:]\n",
        "    gc.collect()\n",
        "    dataset_list.append(train_dataset_temp)\n",
        "\n",
        "train_dataset = dataset_list[0]\n",
        "for i in range(1, c_batch_num):\n",
        "    train_dataset = train_dataset + dataset_list[i]\n",
        "del dataset_list\n",
        "gc.collect()\n",
        "\n",
        "print(\"-\"*20)\n",
        "print(\"train_dataset.__len__() : \", train_dataset.__len__())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiUZDX_9kOV2",
        "outputId": "6eb137f5-fd5c-4982-a312-c91afbe41cbc"
      },
      "outputs": [],
      "source": [
        "#train_dataset = Dataset(np.concatenate((train_state_data, train_action_data), axis=1), train_reward_data)\n",
        "test_dataset = Dataset(np.concatenate((test_state_data, test_action_data), axis=1), test_reward_data)\n",
        "\n",
        "g = torch.Generator().manual_seed(seed)  # 재현성 원하면 지정\n",
        "blocksampler = BlockShuffleSampler(train_dataset, block_size=800, generator=g)\n",
        "\n",
        "#train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=800*8, sampler=blocksampler)\n",
        "test_dataloader = data.DataLoader(dataset=test_dataset, batch_size=800, shuffle=False)\n",
        "\n",
        "#del train_state_data, train_action_data, train_reward_data\n",
        "del test_state_data, test_action_data, test_reward_data\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIXXY-Wo2vfh"
      },
      "source": [
        "## **Training Part**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_hWQJ5WA1Akr",
        "outputId": "db011358-9807-47d6-a29a-476dd3b02458"
      },
      "outputs": [],
      "source": [
        "# hyperparameters blur\n",
        "learning_rate = 8e-5\n",
        "max_epoch = 120\n",
        "print(torch.__file__)\n",
        "\n",
        "model = QValueNet_CNN(input_dim=910, hidden_dim=1024, activation=nn.ELU, dropout=0.15).to(device)\n",
        "summary(model, (1, model.input_dim))\n",
        "\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "#loss_fn = CustomLoss(relative=False, percent=False)\n",
        "#loss_fn = CustomLoss2()\n",
        "loss_fn = CustomLoss3()\n",
        "\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "indv_losses = np.zeros((10, 1))\n",
        "\n",
        "es = EarlyStopping(patience=2000, delta=0.1)\n",
        "for epoch in tqdm(range(max_epoch)):\n",
        "    #print(\"EPOCH \"+str(epoch)+\" TRAINING...\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer, train_loss, es)\n",
        "    #print(\"EPOCH \"+str(epoch)+\" TESTING...\")\n",
        "    indv_losses_temp = []\n",
        "    test_loop(test_dataloader, model, loss_fn, test_loss, indv_losses_temp, epoch)\n",
        "    indv_losses = np.concatenate((indv_losses[:, :], np.expand_dims(np.array(indv_losses_temp), axis=1)), axis=1)\n",
        "\n",
        "    #print(\"\")\n",
        "\n",
        "    if es.early_stop:\n",
        "        print(\"EarlyStop Triggered : Bestscore = {:7.4g}\".format(es.best_score))\n",
        "        break\n",
        "\n",
        "    if (epoch+1)%10 == 0 and epoch != 0:\n",
        "        plt.figure(figsize=(8, 6), dpi=300)\n",
        "        plt.plot(train_loss[2:], label='train_loss')\n",
        "        plt.plot(test_loss[2:], label='test_loss')\n",
        "        for test_idx in range(indv_losses.shape[0]):\n",
        "            plt.plot(indv_losses[test_idx, 2+1:], linestyle='dotted', label=str(test_idx))\n",
        "        plt.ylim(min(np.min(test_loss[2:]), np.min(train_loss[2:]))-0.1, max(np.max(test_loss[2:]), np.max(train_loss[2:]))+0.1)\n",
        "        plt.legend()\n",
        "        plt.title(\"Train/Test Loss (MSE)\")\n",
        "        plt.show()\n",
        "\n",
        "        for i in range(test_img_num):\n",
        "            #if (i > 3 and i < 15) or i > 19:\n",
        "            #    continue\n",
        "            test_img_show(i, loss_fn)\n",
        "\n",
        "        PATH = str(epoch+1)+\"model.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'test_loss': test_loss,\n",
        "        }, PATH)\n",
        "\n",
        "    print(\"[epochs:{:2}]\".format(epoch+2), end='')\n",
        "\n",
        "print(\"DONE\")\n",
        "\n",
        "plt.figure(dpi=300)\n",
        "plt.plot(train_loss[2:], label='train_loss')\n",
        "plt.plot(test_loss[2:], label='test_loss')\n",
        "plt.legend()\n",
        "plt.title(\"Train/Test Loss (MSE)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahNmqGCea_G_",
        "outputId": "35e005ed-d23a-4c6a-ed15-6cf1a1ff4be0"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "train_name = \"train0927_2\"\n",
        "\n",
        "file_list = [f for f in os.listdir(\"/content/\") if f.endswith(\".pt\")] # list of file names to zip\n",
        "output_zip_file = train_name+'.zip' # zip file name\n",
        "\n",
        "with zipfile.ZipFile(output_zip_file, 'w') as zipf:\n",
        "    for file in file_list:\n",
        "        zipf.write(file, os.path.basename(file))\n",
        "\n",
        "print(f\"'{output_zip_file}' file generated.\")\n",
        "\n",
        "np.savez(train_name+\"_losses.npz\", train_loss=train_loss, test_loss=test_loss, indv_losses=indv_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6oDpNqmzXwe"
      },
      "outputs": [],
      "source": [
        "losses_saved = np.load(\"/content/train0927_2_losses.npz\")\n",
        "train_loss = losses_saved['train_loss']\n",
        "test_loss = losses_saved['test_loss']\n",
        "indv_losses = losses_saved['indv_losses']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bcadsftfb5Zh",
        "outputId": "44313ba3-eca0-42bc-b502-9bdf7fe6bb15"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6), dpi=300)\n",
        "plt.plot(train_loss[2:], label='train_loss')\n",
        "plt.plot(test_loss[2:], label='test_loss')\n",
        "for test_idx in range(indv_losses.shape[0]):\n",
        "    plt.plot(indv_losses[test_idx, 2+1:], linestyle='dashdot', label=str(test_idx))\n",
        "#plt.ylim(min(np.min(test_loss[2:]), np.min(train_loss[2:]))-0.1, max(np.max(test_loss[2:]), np.max(train_loss[2:]))+0.1)\n",
        "plt.legend()\n",
        "plt.title(\"Train/Test Loss (MSE)\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 12), dpi=300)\n",
        "plt.plot(train_loss[2:], label='train_loss')\n",
        "plt.plot(test_loss[2:], label='test_loss')\n",
        "for test_idx in range(indv_losses.shape[0]):\n",
        "    if test_idx == 8: continue\n",
        "    plt.plot(indv_losses[test_idx, 2+1:], linestyle='dashdot', label=str(test_idx))\n",
        "\n",
        "#plt.ylim(min(np.min(test_loss[2:]), np.min(train_loss[2:]))-0.1, max(np.max(test_loss[2:]), np.max(train_loss[2:]))+0.1)\n",
        "plt.legend()\n",
        "plt.title(\"Train/Test Loss (MSE)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "7MyZOL-ncSIT",
        "outputId": "96e7272b-0ed9-480c-fbd5-9e47f0fac1a8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6), dpi=300)\n",
        "plt.plot(train_loss[2:], label='train_loss')\n",
        "plt.plot(test_loss[2:], label='test_loss')\n",
        "b_test = np.sum( (np.arange(2, len(test_loss), 1)-np.mean(np.arange(2, len(test_loss), 1)))*(test_loss[2:]-np.mean(test_loss[2:])) ) / np.sum( (np.arange(2, 200, 1)-np.mean(np.arange(2, 200, 1)))**2 )\n",
        "a_test = np.mean(test_loss[2:]) - b_test*np.mean(np.arange(2, len(test_loss), 1))\n",
        "plt.plot(np.arange(2, len(test_loss), 1), a_test+b_test*np.arange(2, len(test_loss), 1), label='test_loss_linear_reg', linestyle='--')\n",
        "plt.ylim(min(np.min(test_loss[2:]), np.min(train_loss[2:]))-0.1, max(np.max(test_loss[2:]), np.max(train_loss[2:]))+0.1)\n",
        "plt.legend()\n",
        "plt.title(\"Train/Test Loss (MSE)\")\n",
        "plt.show()\n",
        "print(\"a_test = \"+str(a_test))\n",
        "print(\"b_test = \"+str(b_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "FNnsi25htf0r",
        "outputId": "84c3551a-5562-44b9-ddbc-78ea0d9b8dc0"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Colab 작업 디렉토리 → 내 드라이브 저장소\n",
        "shutil.move(train_name+\".zip\", \"/content/drive/MyDrive/\"+train_name+\".zip\")\n",
        "shutil.move(train_name+\"_losses.npz\", \"/content/drive/MyDrive/\"+train_name+\"_losses.npz\")\n",
        "\n",
        "!kill -9 -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj7vM1a-1PIW"
      },
      "source": [
        "save no-scaling result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcQSSLJ8nPBO"
      },
      "outputs": [],
      "source": [
        "save_epoch = 100\n",
        "PATH = str(save_epoch)+\"model.pt\"\n",
        "\n",
        "torch.save({\n",
        "    'epoch': save_epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'train_loss': train_loss,\n",
        "    'test_loss': test_loss,\n",
        "}, PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BFdDb36oUjo"
      },
      "source": [
        "Train Continuing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PzGjxD3eoT1I",
        "outputId": "03325e4d-7e67-4015-8bbb-1cecc7f11182"
      },
      "outputs": [],
      "source": [
        "save_epoch = 120\n",
        "PATH = str(save_epoch)+\"model.pt\"\n",
        "\n",
        "# hyperparameters\n",
        "learning_rate = 8e-5\n",
        "max_epoch = 150\n",
        "print(torch.__file__)\n",
        "\n",
        "model = QValueNet_CNN(input_dim=910, hidden_dim=1024, activation=nn.ELU, dropout=0.15).to(device)\n",
        "summary(model, (1, model.input_dim))\n",
        "\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "loss_fn = CustomLoss2()\n",
        "\n",
        "checkpoint = torch.load(PATH, weights_only=True)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch0 = checkpoint['epoch']\n",
        "train_loss = checkpoint['train_loss']\n",
        "test_loss = checkpoint['test_loss']\n",
        "\n",
        "es = EarlyStopping(patience=2000, delta=0.1)\n",
        "for epoch in tqdm(range(max_epoch-save_epoch)):\n",
        "    #print(\"EPOCH \"+str(epoch)+\" TRAINING...\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer, train_loss, es)\n",
        "    #print(\"EPOCH \"+str(epoch)+\" TESTING...\")\n",
        "    indv_losses_temp = []\n",
        "    test_loop(test_dataloader, model, loss_fn, test_loss, indv_losses_temp, epoch)\n",
        "    indv_losses = np.concatenate((indv_losses[:, :], np.expand_dims(np.array(indv_losses_temp), axis=1)), axis=1)\n",
        "\n",
        "    #print(\"\")\n",
        "\n",
        "    if es.early_stop:\n",
        "        print(\"EarlyStop Triggered : Bestscore = {:7.4g}\".format(es.best_score))\n",
        "        break\n",
        "\n",
        "    if (epoch+1)%10 == 0 and epoch != 0:\n",
        "        plt.figure(figsize=(8, 6), dpi=300)\n",
        "        plt.plot(train_loss[2:], label='train_loss')\n",
        "        plt.plot(test_loss[2:], label='test_loss')\n",
        "        for test_idx in range(indv_losses.shape[0]):\n",
        "            plt.plot(indv_losses[test_idx, 2+1:], linestyle='dotted', label=str(test_idx))\n",
        "        plt.ylim(min(np.min(test_loss[2:]), np.min(train_loss[2:]))-0.1, max(np.max(test_loss[2:]), np.max(train_loss[2:]))+0.1)\n",
        "        plt.legend()\n",
        "        plt.title(\"Train/Test Loss (MSE)\")\n",
        "        plt.show()\n",
        "\n",
        "        for i in range(test_img_num):\n",
        "            #if (i > 3 and i < 15) or i > 19:\n",
        "            #    continue\n",
        "            test_img_show(i, loss_fn)\n",
        "\n",
        "        PATH = str(epoch+1)+\"model.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'test_loss': test_loss,\n",
        "        }, PATH)\n",
        "\n",
        "    print(\"[epochs:{:2}]\".format(epoch+2), end='')\n",
        "\n",
        "print(\"DONE\")\n",
        "\n",
        "plt.figure(dpi=300)\n",
        "plt.plot(train_loss[2:], label='train_loss')\n",
        "plt.plot(test_loss[2:], label='test_loss')\n",
        "plt.legend()\n",
        "plt.title(\"Train/Test Loss (MSE)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aia9b3dCWeQ0"
      },
      "outputs": [],
      "source": [
        "for i in range(test_img_num):\n",
        "    test_img_show(i)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
