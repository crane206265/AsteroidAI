{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rybc-_hPmfw"
   },
   "source": [
    "# **Load the Data and Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25516,
     "status": "ok",
     "timestamp": 1753196908268,
     "user": {
      "displayName": "이학진",
      "userId": "17056808516671558306"
     },
     "user_tz": -540
    },
    "id": "RXLi0ehpigHx",
    "outputId": "338b5634-9cbc-4c98-e065-3d0b4fcca4c4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1753197498806,
     "user": {
      "displayName": "이학진",
      "userId": "17056808516671558306"
     },
     "user_tz": -540
    },
    "id": "tB2dPK4s7BOk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import gc\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 2912,
     "status": "ok",
     "timestamp": 1753197503047,
     "user": {
      "displayName": "이학진",
      "userId": "17056808516671558306"
     },
     "user_tz": -540
    },
    "id": "JFRibrGz5Zcr"
   },
   "outputs": [],
   "source": [
    "data_path = \"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_0.npy\"\n",
    "data_RL_preset0 = np.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5172,
     "status": "ok",
     "timestamp": 1753197509533,
     "user": {
      "displayName": "이학진",
      "userId": "17056808516671558306"
     },
     "user_tz": -540
    },
    "id": "Ok0wjI-jq4L-",
    "outputId": "04aa7366-622d-4253-e3f1-25770ad7b553"
   },
   "outputs": [],
   "source": [
    "data_path1 = \"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_1.npy\"\n",
    "data_RL_preset1 = np.load(data_path1)\n",
    "\n",
    "data_RL_preset0[0, 0] = data_RL_preset0[0, 0] + data_RL_preset1[0, 0]\n",
    "data_RL_preset0 = np.concatenate((data_RL_preset0, data_RL_preset1[1:, :]), axis=0)\n",
    "del data_RL_preset1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 2612,
     "status": "ok",
     "timestamp": 1753197513076,
     "user": {
      "displayName": "이학진",
      "userId": "17056808516671558306"
     },
     "user_tz": -540
    },
    "id": "S920S4KYs2Ig"
   },
   "outputs": [],
   "source": [
    "data_path2 = \"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_2.npy\"\n",
    "data_RL_preset2 = np.load(data_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1753197514181,
     "user": {
      "displayName": "이학진",
      "userId": "17056808516671558306"
     },
     "user_tz": -540
    },
    "id": "3aRTxl7UfYFY",
    "outputId": "5b5815ac-ee11-427a-b4e7-51c2d7c495cc"
   },
   "outputs": [],
   "source": [
    "print(data_RL_preset0[0, 0])\n",
    "print(data_RL_preset0[0, 1])\n",
    "print(data_RL_preset0[0, 2])\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1753197213027,
     "user": {
      "displayName": "이학진",
      "userId": "17056808516671558306"
     },
     "user_tz": -540
    },
    "id": "CE_eJhhcVoqh"
   },
   "outputs": [],
   "source": [
    "class RewardMapModifier():\n",
    "    def __init__(self, extends=(0, 1), blur_coef=(5, 3)):\n",
    "        self.extends = extends\n",
    "        self.blur_coef = blur_coef\n",
    "\n",
    "    def extend_hori(self, reward_map, action_maps):\n",
    "        left_reward = reward_map[..., :, -int(reward_map.shape[-2]*self.extends[1]/2):, :]\n",
    "        right_reward = reward_map[..., :, :int(reward_map.shape[-2]*self.extends[1]/2), :]\n",
    "\n",
    "        if action_maps is not None:\n",
    "            left_actions = action_maps[..., :, -int(action_maps.shape[-2]*self.extends[1]/2):, :].copy()\n",
    "            right_actions = action_maps[..., :, :int(action_maps.shape[-2]*self.extends[1]/2), :].copy()\n",
    "            left_actions[..., :, :, 0] = left_actions[..., :, :, 0] - 1\n",
    "            right_actions[..., :, :, 0] = right_actions[..., :, :, 0] + 1\n",
    "\n",
    "        if self.extends[1] != 0:\n",
    "            extended_reward = np.concatenate((left_reward, reward_map, right_reward), axis=-2)\n",
    "            extended_actions = np.concatenate((left_actions, action_maps, right_actions), axis=-2) if action_maps is not None else action_maps\n",
    "        else:\n",
    "            extended_reward = reward_map\n",
    "            extended_actions = action_maps\n",
    "\n",
    "        return extended_reward, extended_actions\n",
    "\n",
    "    def extend_vert(self, reward_map, action_maps):\n",
    "        top_reward = np.flip(reward_map[..., 1:int(reward_map.shape[-3]*self.extends[0]/2), :, :], -3)\n",
    "        bottom_reward = np.flip(reward_map[..., -int(reward_map.shape[-3]*self.extends[0]/2):-1, :, :], -3)\n",
    "\n",
    "        if action_maps is not None:\n",
    "            top_actions = np.flip(action_maps[..., 1:int(action_maps.shape[-3]*self.extends[0]/2), :, :].copy(), -3)\n",
    "            bottom_actions = np.flip(action_maps[..., -int(action_maps.shape[-3]*self.extends[0]/2):-1, :, :].copy(), -3)\n",
    "            top_actions[..., :, :, 1] = 2*0 - top_actions[..., :, :, 1]\n",
    "            bottom_actions[..., :, :, 1] = 2*1 - bottom_actions[..., :, :, 1]\n",
    "\n",
    "        if self.extends[0] != 0:\n",
    "            extended_reward = np.concatenate((top_reward, reward_map, bottom_reward), axis=-3)\n",
    "            extended_actions = np.concatenate((top_actions, action_maps, bottom_actions), axis=-3) if action_maps is not None else action_maps\n",
    "        else:\n",
    "            extended_reward = reward_map\n",
    "            extended_actions = action_maps\n",
    "\n",
    "        return extended_reward, extended_actions\n",
    "\n",
    "    def blur(self, reward_map):\n",
    "        #reward_map = 2.5 * np.tan( reward_map * (np.pi/2) / 6 )\n",
    "        if len(reward_map.shape) == 3:\n",
    "            reward_map[:, :, 0] = cv2.GaussianBlur(reward_map[:, :, 0], (self.blur_coef[0], self.blur_coef[0]), self.blur_coef[1])\n",
    "        elif len(reward_map.shape) == 4:\n",
    "            for i in range(reward_map.shape[0]):\n",
    "                reward_map[i, :, :, 0] = cv2.GaussianBlur(reward_map[i, :, :, 0], (self.blur_coef[0], self.blur_coef[0]), self.blur_coef[1])\n",
    "        reward_map = 6 * (2/np.pi) * np.arctan(reward_map/2)\n",
    "        return reward_map\n",
    "\n",
    "    def operation(self, reward_map, action_maps, order=['extend_hori', 'extend_vert', 'blur']):\n",
    "        result_reward = reward_map\n",
    "        result_action = action_maps\n",
    "        for op in order:\n",
    "            if op == 'extend_hori':\n",
    "                result_reward, result_action = self.extend_hori(result_reward, result_action)\n",
    "            elif op == 'extend_vert':\n",
    "                result_reward, result_action = self.extend_vert(result_reward, result_action)\n",
    "            elif op == 'blur':\n",
    "                result_reward = self.blur(result_reward)\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "        return result_reward, result_action\n",
    "\n",
    "    def ext_N_set(self, N_set):\n",
    "        return (N_set[0]+2*int(N_set[0]*self.extends[1]/2), N_set[1]+2*int(N_set[1]*self.extends[0]/2))\n",
    "\n",
    "\n",
    "class EarlyStopping():\n",
    "    def __init__(self, patience, delta, mode='min'):\n",
    "        \"\"\"\n",
    "        patience : max number of waiting\n",
    "        delta : min boundary of \"change\"\n",
    "        mode :\n",
    "        verbose :\n",
    "        \"\"\"\n",
    "\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.mode = mode\n",
    "        self.best_score = np.inf if mode == 'min' else 0\n",
    "        self.count = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, score):\n",
    "        if self.mode == 'min':\n",
    "            if (self.best_score - score) < self.delta:\n",
    "                self.count += 1\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.count = 0\n",
    "        elif self.mode == 'max':\n",
    "            if (score - self.best_score) < self.delta:\n",
    "                self.count += 1\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.count = 0\n",
    "\n",
    "        if self.count >= self.patience:\n",
    "            self.early_stop = True\n",
    "\n",
    "def data_split(dataset, train_ratio=0.7, shuffle=True, copy=False):\n",
    "    if shuffle:\n",
    "        idx = np.arange(0, dataset.shape[0])\n",
    "        np.random.shuffle(idx)\n",
    "        dataset = dataset[idx]\n",
    "\n",
    "    trainset = dataset[:int(train_ratio*dataset.shape[0])]\n",
    "    testset = dataset[int(train_ratio*dataset.shape[0]):]\n",
    "    if copy:\n",
    "        trainset = trainset.copy()\n",
    "        testset = testset.copy()\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dROAVqHfPwr-"
   },
   "source": [
    "# **Training with Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1753197215723,
     "user": {
      "displayName": "이학진",
      "userId": "17056808516671558306"
     },
     "user_tz": -540
    },
    "id": "_rELvafVHp3v"
   },
   "outputs": [],
   "source": [
    "class QValueNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, activation=nn.ReLU, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.activation = activation\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            activation(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            activation(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            #------------------------------\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            activation(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            #nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            #activation(),\n",
    "            #nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim//4),\n",
    "            activation(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(self.hidden_dim//4, self.hidden_dim//8),\n",
    "            activation(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(self.hidden_dim//8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\"\"\"\n",
    "\n",
    "class QValueNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, activation=nn.ReLU, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.activation = activation\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(3, 3), stride=(1, 1)), #padding 2\n",
    "            activation(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        ) # (1X10X20 -> 1X14X24 (padding)) -> 4X5X10\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), #padding 2\n",
    "            activation(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        ) # 4X5X10 -> 16X2X5\n",
    "\n",
    "        self.linear_model = nn.Sequential(\n",
    "            nn.Linear(459, 512),\n",
    "            activation(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            activation(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            activation(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(512, 1),\n",
    "            activation(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def padding_cir(self, X:torch.Tensor, pad=(2, 2)):\n",
    "        X_new = X.clone()\n",
    "        X_new = torch.cat((X[..., :, -pad[0]:], X_new, X[..., :, :pad[0]]), axis=-1)\n",
    "        X_new = torch.cat((torch.flip(X_new[..., :pad[1], :], [-2]), X_new, torch.flip(X_new[..., -pad[1]:, :], [-2])), axis=-2)\n",
    "\n",
    "        return X_new\n",
    "\n",
    "    def forward(self, X):\n",
    "        X_r_arr = X[..., :200]\n",
    "        if len(X.shape) == 1:\n",
    "            batch_size = 1\n",
    "        else:\n",
    "            batch_size = X.shape[0]\n",
    "        X_r_arr = (X_r_arr.reshape((batch_size, -1, 20, 10))).transpose(-2, -1)/torch.mean(X_r_arr)\n",
    "        X_r_arr_padded = self.padding_cir(X_r_arr, pad=(1, 1))\n",
    "        X_info = X[..., 200:]\n",
    "\n",
    "        x = self.conv1(X_r_arr_padded)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = torch.cat((x, torch.squeeze(X, dim=1)), dim=1)\n",
    "        x = self.linear_model(x)\n",
    "\n",
    "        return x\n",
    "\"\"\"\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, relative, percent):\n",
    "      super().__init__()\n",
    "      self.relative = relative\n",
    "      self.percent = percent\n",
    "\n",
    "    def forward(self, input, target):\n",
    "      torch_MSE = nn.MSELoss()\n",
    "      if self.relative:\n",
    "          loss = torch_MSE(input/(target+1e-6), target/(target+1e-6))\n",
    "          loss = torch.sqrt(loss + 1e-6)\n",
    "      else:\n",
    "          loss = torch.sqrt(torch_MSE(input, target))\n",
    "          #weight = 0.5 + 0.5*torch.abs(target)\n",
    "          #loss = torch.sqrt(torch.sum(weight*(input-target)**2)/torch.sum(weight) + 1e-6)\n",
    "      if self.percent:\n",
    "          loss = 100 * loss\n",
    "      return loss\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, train_loss, es:EarlyStopping):\n",
    "    epoch_loss = 0\n",
    "    n_train = 0\n",
    "\n",
    "    model.train()\n",
    "    #with torch.autograd.detect_anomaly(True):\n",
    "    for X_train, y_train in dataloader:\n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        pred = model(X_train)\n",
    "\n",
    "        non_extended = torch.logical_and((X_train[:, -4] >= 0), (X_train[:, -4] < 1))\n",
    "        non_extended = torch.logical_and(non_extended, (X_train[:, -3] >= 0))\n",
    "        non_extended = torch.logical_and(non_extended, (X_train[:, -3] < 1))\n",
    "        loss = loss_fn(pred[non_extended], y_train[non_extended])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()*X_train.size(0)\n",
    "        n_train += X_train.size(0)\n",
    "\n",
    "    epoch_loss /= n_train\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    es(epoch_loss)\n",
    "    #print(\"train_loss : {:9.4g}\".format(epoch_loss), end=' ')\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, test_loss, epoch):\n",
    "    epoch_loss = 0\n",
    "    n_test = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in dataloader:\n",
    "            X_test = X_test.to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            pred = model(X_test)\n",
    "\n",
    "            non_extended = torch.logical_and((X_test[:, -4] >= 0), (X_test[:, -4] < 1))\n",
    "            non_extended = torch.logical_and(non_extended, (X_test[:, -3] >= 0))\n",
    "            non_extended = torch.logical_and(non_extended, (X_test[:, -3] < 1))\n",
    "            epoch_loss += loss_fn(pred[non_extended], y_test[non_extended]).item()*X_test.size(0)\n",
    "            n_test += X_test.size(0)\n",
    "\n",
    "    epoch_loss /= n_test\n",
    "    test_loss.append(epoch_loss)\n",
    "\n",
    "    print(\"train_loss : {:9.4g}\".format(train_loss[-1]), end=' ')\n",
    "    print(\"| test_loss : {:9.4g}\".format(epoch_loss), end=' ')\n",
    "    print(\"\\n\", end=' ')\n",
    "\n",
    "# Data Processing : scaling data\n",
    "param = [6, 2] #[6, 2.5]\n",
    "def scale_reward(data):\n",
    "    if data_RL_preset0[0, 2] == 1: # already scaled\n",
    "        return data\n",
    "\n",
    "    data_RL_preset0[0, 2] = 1\n",
    "    scaled_data = np.zeros_like(data)\n",
    "\n",
    "    scaled_data = param[0]*(2/np.pi)*np.arctan(data/param[1])\n",
    "\n",
    "    return scaled_data\n",
    "\n",
    "def test_img_show(i_img):\n",
    "    fig = plt.figure(figsize=(16, 8), dpi=300)\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    extent = ( (N_set[0]-ext_N_set[0])/2, (N_set[0]+ext_N_set[0])/2, (N_set[1]-ext_N_set[1])/2, (N_set[1]+ext_N_set[1])/2 )\n",
    "    if i_img == 0 or True:\n",
    "        ax1.clear()\n",
    "        im1 = ax1.imshow(test_img_list[i_img], vmin=-param[0], vmax=param[0], extent=extent)\n",
    "        ax1.set_title(\"TEST_IMAGE_\"+str(i_img))\n",
    "        plt.colorbar(im1, ax=ax1, fraction=0.026, pad=0.04)\n",
    "        ax1.plot([0, N_set[0]],        [0, 0],               color='red', linestyle='solid')\n",
    "        ax1.plot([0, N_set[0]],        [N_set[1], N_set[1]], color='red', linestyle='solid')\n",
    "        ax1.plot([0, 0],               [0, N_set[1]],        color='red', linestyle='solid')\n",
    "        ax1.plot([N_set[0], N_set[0]], [0, N_set[1]],        color='red', linestyle='solid')\n",
    "\n",
    "    reward_map_temp = np.zeros((resol*N_set[0], resol*N_set[1]))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(N_set[0]*N_set[1]*resol*resol):\n",
    "            i = idx//int(resol*N_set[1])\n",
    "            j = idx%int(resol*N_set[1])\n",
    "            phi_action = (i/(resol*N_set[0]))%1\n",
    "            theta_action = (j/(resol*N_set[1]))%1\n",
    "\n",
    "            state = test_img_data[i_img*resol*N_set[0]*N_set[1], :906]\n",
    "            actions = np.array([phi_action, theta_action, 0.1, 0.1])\n",
    "\n",
    "            input = torch.tensor(np.concatenate((state, actions))).float().to(device)\n",
    "            reward = model(input)\n",
    "            reward_map_temp[i, j] = reward\n",
    "    ax2.clear()\n",
    "    im2 = ax2.imshow(reward_map_temp.T)#, vmin=-param[0], vmax=param[0])\n",
    "    ax2.set_title(\"MODEL_OUTPUT_\"+str(i_img))\n",
    "    plt.colorbar(im2, ax=ax2, fraction=0.026, pad=0.04)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1yGwp6IK5zo"
   },
   "source": [
    "### Data Preprocessing with Small Size Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1753197219180,
     "user": {
      "displayName": "이학진",
      "userId": "17056808516671558306"
     },
     "user_tz": -540
    },
    "id": "mTXZcDLp35Rv"
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        super(Dataset, self).__init__()\n",
    "\n",
    "        if not torch.is_tensor(x_tensor):\n",
    "            self.x = torch.tensor(x_tensor).float()\n",
    "            self.y = torch.tensor(y_tensor).float()\n",
    "        else:\n",
    "            self.x = x_tensor.float()\n",
    "            self.y = y_tensor.float()\n",
    "\n",
    "    def __getitem__(self, index): return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self): return self.x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17108,
     "status": "ok",
     "timestamp": 1753197536073,
     "user": {
      "displayName": "이학진",
      "userId": "17056808516671558306"
     },
     "user_tz": -540
    },
    "id": "OFVzgiMgUc4D",
    "outputId": "88a86c8d-c4ec-4159-c734-95f51a945151"
   },
   "outputs": [],
   "source": [
    "# seed\n",
    "seed = 722\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 1024\n",
    "learning_rate = 6e-5\n",
    "max_epoch = 1000\n",
    "\n",
    "# other parameters\n",
    "N_set = (40, 20)\n",
    "resol = 1\n",
    "\n",
    "map_modifier = RewardMapModifier(extends=(0, 0), blur_coef=(3, 2))\n",
    "chunk_size = 256\n",
    "chunk_set_size = chunk_size*N_set[0]*N_set[1]\n",
    "online_dataset_path = \"/content/gdrive/MyDrive/Asteroid RL dataset/online_dataset/\"\n",
    "\n",
    "\n",
    "data_len2 = int(data_RL_preset2[0, 0])\n",
    "test_img_num = 10\n",
    "test_img_idx_choice = np.random.randint(0, (data_len2-1)//800, 10)\n",
    "dataset_img_idx = np.full(data_len2, False)\n",
    "for i in test_img_idx_choice:\n",
    "    dataset_img_idx[i*800+1:(i+1)*800+1] = True\n",
    "\n",
    "data_RL_preset = data_RL_preset0[1:, :]\n",
    "test_img_data = data_RL_preset2[dataset_img_idx, :].copy()\n",
    "del data_RL_preset2\n",
    "gc.collect()\n",
    "\n",
    "test_img_list = []\n",
    "for i in range(test_img_num):\n",
    "    test_img_list.append(test_img_data[i*resol*N_set[0]*N_set[1]:(i+1)*resol*N_set[0]*N_set[1], -1].reshape((N_set[0], N_set[1])).T)\n",
    "\n",
    "for i in range(len(test_img_list)):\n",
    "    test_img_list[i], _ = map_modifier.operation(np.expand_dims(test_img_list[i], axis=-1), None, order=['extend_hori', 'extend_vert', 'blur'])\n",
    "    #test_img_list[i] = test_img_list[i][:, :, 0]\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "cut = N_set[0]*N_set[1]*2093 + 1 #1040\n",
    "state_data = data_RL_preset[:cut, :-5]\n",
    "action_data = data_RL_preset[:cut, -5:-1]\n",
    "reward_data = data_RL_preset[:cut, -1:]\n",
    "\n",
    "\n",
    "new_action_data = 0 * np.array([action_data[0, ...].copy()])\n",
    "new_reward_data = 0 * np.array([reward_data[0, ...].copy()])\n",
    "\n",
    "print(\"Data Shapes Before Map Modifying\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"state_data  | \"+str(state_data.shape)+\", \"+str(int(1000*state_data.itemsize*state_data.size/(2**30))/1000)+\"GB\")\n",
    "print(\"action_data | \"+str(action_data.shape)+\"  , \"+str(int(1000*action_data.itemsize*action_data.size/(2**30))/1000)+\"GB\")\n",
    "print(\"reward_data | \"+str(reward_data.shape)+\"  , \"+str(int(1000*reward_data.itemsize*reward_data.size/(2**30))/1000)+\"GB\")\n",
    "\n",
    "print(\"\\n--------------------------------\")\n",
    "for i in range(math.ceil(state_data.shape[0]/chunk_set_size)):\n",
    "    if i != state_data.shape[0]//(chunk_size*N_set[0]*N_set[1]):\n",
    "        reward_map = reward_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
    "        action_maps = action_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
    "    else:\n",
    "        reward_map = reward_data[chunk_set_size*i:]\n",
    "        action_maps = action_data[chunk_set_size*i:]\n",
    "\n",
    "    print(\"Batch Shape : reward / action | \"+str(reward_map.shape)+\", \"+str(action_maps.shape)+\" --> \", end='')\n",
    "    reward_map = np.swapaxes(reward_map.reshape((-1, N_set[0], N_set[1], 1)), -2, -3)\n",
    "    action_maps = np.swapaxes(action_maps.reshape((-1, N_set[0], N_set[1], 4)), -2, -3)\n",
    "    reward_map, action_maps = map_modifier.operation(reward_map, action_maps, order=['extend_hori', 'extend_vert', 'blur'])\n",
    "    print(str(reward_map.shape)+\", \"+str(action_maps.shape))\n",
    "\n",
    "    extended_size = reward_map.shape[-2] * reward_map.shape[-3]\n",
    "    new_action_data = np.concatenate((new_action_data, action_maps.reshape(-1, 4)), axis=0)\n",
    "    new_reward_data = np.concatenate((new_reward_data, reward_map.reshape(-1, 1)), axis=0)\n",
    "print(\"--------------------------------\\n\")\n",
    "\n",
    "state_data = np.repeat(state_data[::N_set[0]*N_set[1]], repeats=extended_size, axis=0)\n",
    "action_data = np.delete(new_action_data, 0, axis=0)\n",
    "reward_data = np.delete(new_reward_data, 0, axis=0)\n",
    "\n",
    "del new_action_data, new_reward_data, reward_map, action_maps\n",
    "del data_RL_preset, data_RL_preset0\n",
    "gc.collect()\n",
    "\n",
    "print(\"Data Shapes After Map Mpdifying\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"state_data  | \"+str(state_data.shape)+\", \"+str(int(1000*state_data.itemsize*state_data.size/(2**30))/1000)+\"GB\")\n",
    "print(\"action_data | \"+str(action_data.shape)+\"  , \"+str(int(1000*action_data.itemsize*action_data.size/(2**30))/1000)+\"GB\")\n",
    "print(\"reward_data | \"+str(reward_data.shape)+\"  , \"+str(int(1000*reward_data.itemsize*reward_data.size/(2**30))/1000)+\"GB\")\n",
    "\n",
    "ext_N_set = map_modifier.ext_N_set(N_set)\n",
    "\n",
    "\n",
    "total_data = np.concatenate((state_data, action_data, reward_data), axis=1)\n",
    "state_shape = state_data.shape[1]\n",
    "del state_data, action_data, reward_data\n",
    "gc.collect()\n",
    "\n",
    "train_data, test_data = data_split(total_data, train_ratio=0.85, shuffle=True, copy=True)\n",
    "del total_data\n",
    "gc.collect()\n",
    "\n",
    "train_state_data = train_data[:, :state_shape].copy()\n",
    "train_action_data = train_data[:, state_shape:state_shape+4].copy()\n",
    "train_reward_data = train_data[:, -1].reshape(-1, 1)\n",
    "del train_data\n",
    "gc.collect()\n",
    "\n",
    "test_state_data = test_data[:, :state_shape].copy()\n",
    "test_action_data = test_data[:, state_shape:state_shape+4].copy()\n",
    "test_reward_data = test_data[:, -1].reshape(-1, 1)\n",
    "del test_data\n",
    "gc.collect()\n",
    "\n",
    "train_dataset = Dataset(np.concatenate((train_state_data, train_action_data), axis=1), train_reward_data)\n",
    "test_dataset = Dataset(np.concatenate((test_state_data, test_action_data), axis=1), test_reward_data)\n",
    "\n",
    "train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "del train_state_data, train_action_data, train_reward_data\n",
    "del test_state_data, test_action_data, test_reward_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIXXY-Wo2vfh"
   },
   "source": [
    "## **Training Part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "p78XOj3VmW8q",
    "outputId": "cd47b92a-096d-4d79-d500-93c47a8492db"
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 8e-5\n",
    "max_epoch = 400\n",
    "print(torch.__file__)\n",
    "\n",
    "model = QValueNet(input_dim=910, hidden_dim=1024, activation=nn.ELU, dropout=0.15).to(device)\n",
    "summary(model, (1, model.input_dim))\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "loss_fn = CustomLoss(relative=False, percent=False)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "es = EarlyStopping(patience=2000, delta=0.1)\n",
    "for epoch in tqdm(range(max_epoch)):\n",
    "    #print(\"EPOCH \"+str(epoch)+\" TRAINING...\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, train_loss, es)\n",
    "    #print(\"EPOCH \"+str(epoch)+\" TESTING...\")\n",
    "    test_loop(test_dataloader, model, loss_fn, test_loss, epoch)\n",
    "    #print(\"\")\n",
    "\n",
    "    if es.early_stop:\n",
    "        print(\"EarlyStop Triggered : Bestscore = {:7.4g}\".format(es.best_score))\n",
    "        break\n",
    "\n",
    "    if (epoch+1)%10 == 0 and epoch != 0:\n",
    "        plt.figure(figsize=(5, 3), dpi=300)\n",
    "        plt.plot(train_loss[2:], label='train_loss')\n",
    "        plt.plot(test_loss[2:], label='test_loss')\n",
    "        plt.legend()\n",
    "        plt.title(\"Train/Test Loss (MSE)\")\n",
    "        plt.show()\n",
    "\n",
    "        for i in range(test_img_num):\n",
    "            #if (i > 3 and i < 15) or i > 19:\n",
    "            #    continue\n",
    "            test_img_show(i)\n",
    "\n",
    "    print(\"[epochs:{:2}]\".format(epoch+2), end='')\n",
    "\n",
    "print(\"DONE\")\n",
    "\n",
    "plt.figure(dpi=300)\n",
    "plt.plot(train_loss[2:], label='train_loss')\n",
    "plt.plot(test_loss[2:], label='test_loss')\n",
    "plt.legend()\n",
    "plt.title(\"Train/Test Loss (MSE)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "aia9b3dCWeQ0"
   },
   "outputs": [],
   "source": [
    "for i in range(test_img_num):\n",
    "    test_img_show(i)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "HBqbzM47LGZE",
    "qyACgjD5P-ml"
   ],
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
