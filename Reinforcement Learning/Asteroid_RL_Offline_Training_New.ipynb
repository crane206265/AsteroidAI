{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rybc-_hPmfw"
      },
      "source": [
        "# **Load the Data and Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RXLi0ehpigHx",
        "outputId": "d6e3b86e-1902-4e95-d61d-10284295112f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB2dPK4s7BOk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils import data\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import math\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "import gc\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFRibrGz5Zcr"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_0.npy\"\n",
        "data_RL_preset0 = np.load(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ok0wjI-jq4L-",
        "outputId": "caedcf34-f3fa-45d5-b0fc-827c24c103ce"
      },
      "outputs": [],
      "source": [
        "data_path1 = \"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_1.npy\"\n",
        "data_RL_preset1 = np.load(data_path1)\n",
        "\n",
        "data_RL_preset0[0, 0] = data_RL_preset0[0, 0] + data_RL_preset1[0, 0]\n",
        "data_RL_preset0 = np.concatenate((data_RL_preset0, data_RL_preset1[1:, :]), axis=0)\n",
        "del data_RL_preset1\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S920S4KYs2Ig"
      },
      "outputs": [],
      "source": [
        "data_path2 = \"/content/gdrive/MyDrive/Asteroid RL dataset/new_RL_preset/data_pole_axis_RL_preset_batch_2.npy\"\n",
        "data_RL_preset2 = np.load(data_path2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3aRTxl7UfYFY",
        "outputId": "2f26e674-3aa6-40c4-bc4f-bb1258175ea6"
      },
      "outputs": [],
      "source": [
        "print(data_RL_preset0[0, 0])\n",
        "print(data_RL_preset0[0, 1])\n",
        "print(data_RL_preset0[0, 2])\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CE_eJhhcVoqh"
      },
      "outputs": [],
      "source": [
        "class RewardMapModifier():\n",
        "    def __init__(self, extends=(0, 1), blur_coef=(5, 3)):\n",
        "        self.extends = extends\n",
        "        self.blur_coef = blur_coef\n",
        "\n",
        "    def extend_hori(self, reward_map, action_maps):\n",
        "        left_reward = reward_map[..., :, -int(reward_map.shape[-2]*self.extends[1]/2):, :]\n",
        "        right_reward = reward_map[..., :, :int(reward_map.shape[-2]*self.extends[1]/2), :]\n",
        "\n",
        "        if action_maps is not None:\n",
        "            left_actions = action_maps[..., :, -int(action_maps.shape[-2]*self.extends[1]/2):, :].copy()\n",
        "            right_actions = action_maps[..., :, :int(action_maps.shape[-2]*self.extends[1]/2), :].copy()\n",
        "            left_actions[..., :, :, 0] = left_actions[..., :, :, 0] - 1\n",
        "            right_actions[..., :, :, 0] = right_actions[..., :, :, 0] + 1\n",
        "\n",
        "        if self.extends[1] != 0:\n",
        "            extended_reward = np.concatenate((left_reward, reward_map, right_reward), axis=-2)\n",
        "            extended_actions = np.concatenate((left_actions, action_maps, right_actions), axis=-2) if action_maps is not None else action_maps\n",
        "        else:\n",
        "            extended_reward = reward_map\n",
        "            extended_actions = action_maps\n",
        "\n",
        "        return extended_reward, extended_actions\n",
        "\n",
        "    def extend_vert(self, reward_map, action_maps):\n",
        "        top_reward = np.roll(reward_map[..., :int(reward_map.shape[-3]*self.extends[0]/2), :, :], 20, axis=-2)\n",
        "        bottom_reward = np.roll(reward_map[..., -int(reward_map.shape[-3]*self.extends[0]/2):, :, :], 20, axis=-2)\n",
        "        top_reward = np.flip(top_reward, axis=-3)\n",
        "        bottom_reward = np.flip(bottom_reward, axis=-3)\n",
        "\n",
        "        if action_maps is not None:\n",
        "            top_actions = np.flip(action_maps[..., :int(action_maps.shape[-3]*self.extends[0]/2), :, :].copy(), -3)\n",
        "            bottom_actions = np.flip(action_maps[..., -int(action_maps.shape[-3]*self.extends[0]/2):, :, :].copy(), -3)\n",
        "            top_actions[..., :, :, 1] = 2*0 - top_actions[..., :, :, 1]\n",
        "            bottom_actions[..., :, :, 1] = 2*1 - bottom_actions[..., :, :, 1]\n",
        "\n",
        "        if self.extends[0] != 0:\n",
        "            extended_reward = np.concatenate((top_reward, reward_map, bottom_reward), axis=-3)\n",
        "            extended_actions = np.concatenate((top_actions, action_maps, bottom_actions), axis=-3) if action_maps is not None else action_maps\n",
        "        else:\n",
        "            extended_reward = reward_map\n",
        "            extended_actions = action_maps\n",
        "\n",
        "        return extended_reward, extended_actions\n",
        "\n",
        "    def blur(self, reward_map):\n",
        "        #reward_map = 2.5 * np.tan( reward_map * (np.pi/2) / 6 )\\n\",\n",
        "        if len(reward_map.shape) == 3:\n",
        "            reward_map[:, :, 0] = cv2.GaussianBlur(reward_map[:, :, 0], (self.blur_coef[0], self.blur_coef[0]), self.blur_coef[1])\n",
        "        elif len(reward_map.shape) == 4:\n",
        "            for i in range(reward_map.shape[0]):\n",
        "                reward_map[i, :, :, 0] = cv2.GaussianBlur(reward_map[i, :, :, 0], (self.blur_coef[0], self.blur_coef[0]), self.blur_coef[1])\n",
        "                #max_val = np.max(np.abs(reward_map[i, :, :, 0]))\n",
        "                #reward_map[i, :, :, 0] = 6 * (2/np.pi) * np.arctan(reward_map[i, :, :, 0]/2) / ((2/np.pi) * np.arctan(max_val/2))\n",
        "        #reward_map = 6 * (2/np.pi) * np.arctan(reward_map/8)\n",
        "        #reward_map = 6 * 2*(1/(1+np.exp(-reward_map/7)) - 0.5)\n",
        "        reward_map = 6 * (2/np.pi) * np.arctan(reward_map/2)\n",
        "        return reward_map\n",
        "\n",
        "    def operation(self, reward_map, action_maps, order=['extend_hori', 'extend_vert', 'blur']):\n",
        "        result_reward = reward_map\n",
        "        result_action = action_maps\n",
        "        for op in order:\n",
        "            if op == 'extend_hori':\n",
        "                result_reward, result_action = self.extend_hori(result_reward, result_action)\n",
        "            elif op == 'extend_vert':\n",
        "                result_reward, result_action = self.extend_vert(result_reward, result_action)\n",
        "            elif op == 'blur':\n",
        "                result_reward = self.blur(result_reward)\n",
        "            else:\n",
        "                raise NotImplementedError()\n",
        "        return result_reward, result_action\n",
        "\n",
        "    def ext_N_set(self, N_set):\n",
        "        return (N_set[0]+2*int(N_set[0]*self.extends[1]/2), N_set[1]+2*int(N_set[1]*self.extends[0]/2))\n",
        "\n",
        "class EarlyStopping():\n",
        "    def __init__(self, patience, delta, mode='min'):\n",
        "        \"\"\"\n",
        "        patience : max number of waiting\n",
        "        delta : min boundary of \"change\"\n",
        "        mode :\n",
        "        verbose :\n",
        "        \"\"\"\n",
        "\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.mode = mode\n",
        "        self.best_score = np.inf if mode == 'min' else 0\n",
        "        self.count = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, score):\n",
        "        if self.mode == 'min':\n",
        "            if (self.best_score - score) < self.delta:\n",
        "                self.count += 1\n",
        "            else:\n",
        "                self.best_score = score\n",
        "                self.count = 0\n",
        "        elif self.mode == 'max':\n",
        "            if (score - self.best_score) < self.delta:\n",
        "                self.count += 1\n",
        "            else:\n",
        "                self.best_score = score\n",
        "                self.count = 0\n",
        "\n",
        "        if self.count >= self.patience:\n",
        "            self.early_stop = True\n",
        "\n",
        "def data_split(dataset, train_ratio=0.7, shuffle=True, copy=False):\n",
        "    if shuffle:\n",
        "        idx = np.arange(0, dataset.shape[0])\n",
        "        np.random.shuffle(idx)\n",
        "        dataset = dataset[idx]\n",
        "\n",
        "    trainset = dataset[:int(train_ratio*dataset.shape[0])]\n",
        "    testset = dataset[int(train_ratio*dataset.shape[0]):]\n",
        "    if copy:\n",
        "        trainset = trainset.copy()\n",
        "        testset = testset.copy()\n",
        "\n",
        "    return trainset, testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dROAVqHfPwr-"
      },
      "source": [
        "# **Training with Regression Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rELvafVHp3v"
      },
      "outputs": [],
      "source": [
        "class QValueNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=512, activation=nn.ReLU, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.activation = activation\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, self.hidden_dim),\n",
        "            activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            #------------------------------\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            #nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            #activation(),\n",
        "            #nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim//4),\n",
        "            activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(self.hidden_dim//4, self.hidden_dim//8),\n",
        "            activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(self.hidden_dim//8, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.model(X)\n",
        "\n",
        "\n",
        "class QValueNet_CNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=512, activation=nn.ReLU, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.activation = activation\n",
        "\n",
        "        # R_arr encoders (input: [B, C, 40, 20])\n",
        "        self.r_arr_encoder1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, (9, 5)),  # 1 channel / assumed input is already done padding=1 #(1, 16, 3)\n",
        "            self.activation(),\n",
        "            nn.MaxPool2d(2)  # -> 20×10\n",
        "        )\n",
        "\n",
        "        self.r_arr_encoder2 = nn.Sequential(\n",
        "            nn.Conv2d(8, 16, (5, 3)),  # assumed input is already done padding=1 #(16, 32, 3)\n",
        "            self.activation(),\n",
        "            nn.Flatten(),     # -> 16×20×10 = 3200  # -> 32×20×10 = 6400\n",
        "            nn.Linear(3200, 1024)\n",
        "        )\n",
        "\n",
        "        # Info encoder (input: [B, 1, 6])\n",
        "        self.info_encoder = nn.Sequential(\n",
        "            nn.Linear(6, 32),\n",
        "            self.activation(),\n",
        "            nn.Linear(32, 64)\n",
        "        )\n",
        "\n",
        "        # RL encoder (input: [B, 1, 4])\n",
        "        self.rl_encoder = nn.Sequential(\n",
        "            nn.Linear(4, 32),\n",
        "            self.activation(),\n",
        "            nn.Linear(32, 64)\n",
        "        )\n",
        "\n",
        "        # Lightcurves encoder (input: [B, 1, 100])\n",
        "        self.lc_encoder1 = nn.Sequential(\n",
        "            nn.Conv1d(1, 16, kernel_size=15),\n",
        "            self.activation(),\n",
        "            nn.MaxPool1d(2),   # → 50\n",
        "        )\n",
        "\n",
        "        self.lc_encoder2 = nn.Sequential(\n",
        "            nn.Conv1d(16, 32, kernel_size=9),\n",
        "            self.activation(),\n",
        "            nn.Flatten(),      # → 32×50\n",
        "            nn.Linear(32*50, 256)\n",
        "        )\n",
        "\n",
        "        # Fusion & Head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(1024 + 256 + 64 + 64, 1024),\n",
        "            self.activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            #nn.Linear(1024, 1024),\n",
        "            #self.activation(),\n",
        "            #nn.Dropout(dropout), #//// 새로 추가\n",
        "\n",
        "            nn.Linear(1024, 256),\n",
        "            self.activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(256, 1)  # e.g., class count or regression value\n",
        "        )\n",
        "\n",
        "    def r_padding(self, x, pad=(1, 1)):\n",
        "        N, C, H, W = x.shape\n",
        "        pad_H = pad[0]\n",
        "        pad_W = pad[1]\n",
        "\n",
        "        out = torch.full((N, C, H + 2*pad_H, W + 2*pad_W), fill_value=0.0, dtype=x.dtype, device=x.device)\n",
        "        out[:, :, pad_H:pad_H+H, pad_W:pad_W+W] = x\n",
        "        out[:, :, :, :pad_W] = torch.roll(torch.flip(out[:, :, :, pad_W:pad_W+pad_W], (-2,)), 20, -1)\n",
        "        out[:, :, :, -pad_W:] = torch.roll(torch.flip(out[:, :, :, -pad_W-pad_W:-pad_W], (-2,)), 20, -1)\n",
        "        out[:, :, :pad_H, pad_W:pad_W+W] = x[:, :, -pad_H:, :]\n",
        "        out[:, :, -pad_H:, pad_W:pad_W+W] = x[:, :, :pad_H, :]\n",
        "        return out\n",
        "\n",
        "    def lc_padding(self, x, pad=1):\n",
        "        N, C, W = x.shape\n",
        "\n",
        "        out = torch.full((N, C, W + 2*pad), fill_value=0.0, dtype=x.dtype, device=x.device)\n",
        "        out[:, :, pad:pad+W] = x\n",
        "        out[:, :, :pad] = x[:, :, -pad:]\n",
        "        out[:, :, -pad:] = x[:, :, :pad]\n",
        "        return out\n",
        "\n",
        "    def forward(self, X):\n",
        "        r_arr = X[..., :800].reshape((X.shape[0], 1, 40, 20))\n",
        "        lc_arr = X[..., 800:900].reshape((X.shape[0], 1, 100))\n",
        "        lc_info = X[..., 900:906]\n",
        "        rl_info = X[..., 906:]\n",
        "\n",
        "        r_arr_feat = torch.transpose(r_arr, -2, -1)\n",
        "        r_arr_feat = self.r_padding(r_arr_feat, pad=(4, 2))\n",
        "        r_arr_feat = self.r_arr_encoder1(r_arr_feat)\n",
        "        r_arr_feat = self.r_padding(r_arr_feat, pad=(2, 1))\n",
        "        r_arr_feat = self.r_arr_encoder2(r_arr_feat)\n",
        "\n",
        "        lc_feat = self.lc_padding(lc_arr, pad=7)\n",
        "        lc_feat = self.lc_encoder1(lc_feat)\n",
        "        lc_feat = self.lc_padding(lc_feat, pad=4)\n",
        "        lc_feat = self.lc_encoder2(lc_feat)\n",
        "\n",
        "        info_feat = self.info_encoder(lc_info)\n",
        "        info_feat = torch.squeeze(info_feat, dim=1)\n",
        "\n",
        "        rl_feat = self.rl_encoder(rl_info)\n",
        "        rl_feat = torch.squeeze(rl_feat, dim=1)\n",
        "\n",
        "        fusion_feat = torch.cat((r_arr_feat, lc_feat, info_feat, rl_feat), dim=1)\n",
        "        out = self.head(fusion_feat)\n",
        "\n",
        "        PI = 3.14159265358979\n",
        "        out = 6 * 2 / PI * torch.atan(2 * out) #out/0.8\n",
        "        #out = 7 * 2 / PI * torch.atan(1.5 * out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self, relative, percent):\n",
        "      super().__init__()\n",
        "      self.relative = relative\n",
        "      self.percent = percent\n",
        "\n",
        "    def forward(self, input, target):\n",
        "      torch_MSE = nn.MSELoss()\n",
        "      if self.relative:\n",
        "          loss = torch_MSE(input/(target+1e-6), target/(target+1e-6))\n",
        "          loss = torch.sqrt(loss + 1e-6)\n",
        "      else:\n",
        "          loss = torch.sqrt(torch_MSE(input, target))\n",
        "          #weight = 0.5 + 0.5*torch.abs(target)\n",
        "          #loss = torch.sum(weight*(input-target)**2)/torch.sum(weight)\n",
        "          #loss = torch.sqrt(loss + 1e-6)\n",
        "      if self.percent:\n",
        "          loss = 100 * loss\n",
        "      return loss\n",
        "\n",
        "class CustomLoss1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        torch_MSE = nn.MSELoss()\n",
        "        input_prop = self.processer(input)\n",
        "        target_prop = self.processer(target)\n",
        "\n",
        "        #input_prop_pos = torch.where(input_prop > 0, input_prop, 0)\n",
        "        #input_prop_neg = torch.where(input_prop < 0, input_prop, 0)\n",
        "        #input_prop_final = input_prop_pos*torch.max(target_prop)/(torch.max(input_prop_pos)+1e-6) + input_prop_neg*torch.min(target_prop)/(torch.min(input_prop_neg)+1e-6)\n",
        "        #target_prop_pos = torch.where(target_prop > 0, target_prop, 0)\n",
        "        #target_prop_neg = torch.where(target_prop < 0, target_prop, 0)\n",
        "        #target_prop_final = target_prop_pos*torch.max(input_prop)/(torch.max(target_prop_pos)+1e-6) + target_prop_neg*torch.min(input_prop)/(torch.min(target_prop_neg)+1e-6)\n",
        "\n",
        "        loss = torch_MSE(input_prop, target_prop)\n",
        "        return 1e+6 * loss\n",
        "\n",
        "    def processer(self, reward_map):\n",
        "        hori_prop, vert_prop = 3, 3\n",
        "        reward_map_pos = torch.where(reward_map > 0, reward_map, 0)\n",
        "        reward_map_neg = torch.where(reward_map < 0, reward_map, 0)\n",
        "\n",
        "        exp = 2\n",
        "        div = hori_prop + vert_prop - 0.5\n",
        "        reward_map_prop = reward_map_pos**exp\n",
        "        for i in range(1, hori_prop+1):\n",
        "            reward_map_prop[:, :-i] = reward_map_prop[:, :-i] + reward_map_pos[:, i:]**exp\n",
        "            reward_map_prop[:,  i:] = reward_map_prop[:,  i:] + reward_map_pos[:, :-i]**exp\n",
        "        for j in range(1, vert_prop+1):\n",
        "            reward_map_prop[:-j, :] = reward_map_prop[:-j, :] + reward_map_pos[j:, :]**exp\n",
        "            reward_map_prop[ j:, :] = reward_map_prop[ j:, :] + reward_map_pos[:-j, :]**exp\n",
        "        reward_map_prop = (reward_map_prop / div)**(1/exp)\n",
        "        reward_map_prop = reward_map_prop + reward_map_neg\n",
        "\n",
        "        return reward_map_prop\n",
        "\n",
        "class CustomLoss2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.epoch = 0\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        torch_MSE = nn.MSELoss()\n",
        "        input_prop = self.processer(input)\n",
        "        target_prop = self.processer(target)\n",
        "\n",
        "        eps = 0.3\n",
        "        input_prop_pos = torch.where(input_prop > 0, input_prop, 0)\n",
        "        input_prop_neg = torch.where(input_prop < 0, input_prop, 0)\n",
        "        input_prop_final = input_prop_pos*torch.max(target_prop)/(torch.max(input_prop_pos)+eps) + input_prop_neg*torch.min(target_prop)/(torch.min(input_prop_neg)+eps)\n",
        "        #target_prop_pos = torch.where(target_prop > 0, target_prop, 0)\n",
        "        #target_prop_neg = torch.where(target_prop < 0, target_prop, 0)\n",
        "        #target_prop_final = target_prop_pos*torch.max(input_prop)/(torch.max(target_prop_pos)+1e-6) + target_prop_neg*torch.min(input_prop)/(torch.min(target_prop_neg)+1e-6)\n",
        "\n",
        "        loss = torch_MSE(input_prop, target_prop)\n",
        "        return loss\n",
        "\n",
        "    def processer(self, reward_map):\n",
        "        hori_prop, vert_prop = 3, 3\n",
        "        reward_map_pos = torch.where(reward_map > 0, reward_map, 0)\n",
        "        reward_map_neg = torch.where(reward_map < 0, reward_map, 0)\n",
        "\n",
        "        exp = 2\n",
        "        div = hori_prop + vert_prop - 0.5\n",
        "        reward_map_prop = reward_map_pos**exp\n",
        "        for i in range(1, hori_prop+1):\n",
        "            reward_map_prop[:, :-i] = reward_map_prop[:, :-i] + reward_map_pos[:, i:]**exp\n",
        "            reward_map_prop[:,  i:] = reward_map_prop[:,  i:] + reward_map_pos[:, :-i]**exp\n",
        "        for j in range(1, vert_prop+1):\n",
        "            reward_map_prop[:-j, :] = reward_map_prop[:-j, :] + reward_map_pos[j:, :]**exp\n",
        "            reward_map_prop[ j:, :] = reward_map_prop[ j:, :] + reward_map_pos[:-j, :]**exp\n",
        "        reward_map_prop = (reward_map_prop / div)**(1/exp)\n",
        "        reward_map_prop = reward_map_prop + reward_map_neg\n",
        "\n",
        "        return reward_map_prop\n",
        "\n",
        "    def setepoch(self, epoch):\n",
        "        self.epoch = epoch\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer, train_loss, es:EarlyStopping):\n",
        "    epoch_loss = 0\n",
        "    n_train = 0\n",
        "\n",
        "    model.train()\n",
        "    #with torch.autograd.detect_anomaly(True):\n",
        "    for X_train, y_train in dataloader:\n",
        "        X_train = X_train.to(device)\n",
        "        y_train = y_train.to(device)\n",
        "        pred = model(X_train)\n",
        "\n",
        "        #non_extended = torch.logical_and((X_train[:, -4] >= 0), (X_train[:, -4] < 1))\n",
        "        #non_extended = torch.logical_and(non_extended, (X_train[:, -3] >= 0))\n",
        "        #non_extended = torch.logical_and(non_extended, (X_train[:, -3] < 1))\n",
        "        #loss = loss_fn(pred[non_extended], y_train[non_extended])\n",
        "        loss = loss_fn(pred, y_train)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()*X_train.size(0)\n",
        "        n_train += X_train.size(0)\n",
        "\n",
        "    epoch_loss /= n_train\n",
        "    train_loss.append(epoch_loss)\n",
        "\n",
        "    es(epoch_loss)\n",
        "    #print(\"train_loss : {:9.4g}\".format(epoch_loss), end=' ')\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn, test_loss, epoch):\n",
        "    epoch_loss = 0\n",
        "    n_test = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X_test, y_test in dataloader:\n",
        "            X_test = X_test.to(device)\n",
        "            y_test = y_test.to(device)\n",
        "            pred = model(X_test)\n",
        "\n",
        "            #non_extended = torch.logical_and((X_test[:, -4] >= 0), (X_test[:, -4] < 1))\n",
        "            #non_extended = torch.logical_and(non_extended, (X_test[:, -3] >= 0))\n",
        "            #non_extended = torch.logical_and(non_extended, (X_test[:, -3] < 1))\n",
        "            #epoch_loss += loss_fn(pred[non_extended], y_test[non_extended]).item()*X_test.size(0)\n",
        "\n",
        "            #epoch_loss += loss_fn(pred, y_test).item()*X_test.size(0)\n",
        "            epoch_loss += loss_fn(torch.transpose(pred.reshape(40, 20), 0, 1), torch.transpose(y_test.reshape(40, 20), 0, 1)).item()*X_test.size(0)\n",
        "            n_test += X_test.size(0)\n",
        "\n",
        "    epoch_loss /= n_test\n",
        "    test_loss.append(epoch_loss)\n",
        "\n",
        "    print(\"train_loss : {:9.4g}\".format(train_loss[-1]), end=' ')\n",
        "    print(\"| test_loss : {:9.4g}\".format(epoch_loss), end=' ')\n",
        "    print(\"\\n\", end=' ')\n",
        "\n",
        "# Data Processing : scaling data\n",
        "param = [6, 2] #[6, 2.5]\n",
        "def scale_reward(data):\n",
        "    if data_RL_preset0[0, 2] == 1: # already scaled\n",
        "        return data\n",
        "\n",
        "    data_RL_preset0[0, 2] = 1\n",
        "    scaled_data = np.zeros_like(data)\n",
        "\n",
        "    scaled_data = param[0]*(2/np.pi)*np.arctan(data/param[1])\n",
        "\n",
        "    return scaled_data\n",
        "\n",
        "def test_img_show(i_img, loss_fn):\n",
        "    fig = plt.figure(figsize=(16, 8), dpi=300)\n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "    ax2 = fig.add_subplot(1, 2, 2)\n",
        "\n",
        "    extent = ( (N_set[0]-ext_N_set[0])/2, (N_set[0]+ext_N_set[0])/2, (N_set[1]+ext_N_set[1])/2, (N_set[1]-ext_N_set[1])/2 )\n",
        "    if i_img == 0 or True:\n",
        "        ax1.clear()\n",
        "        im1 = ax1.imshow(test_img_list[i_img], vmin=-param[0], vmax=param[0], extent=extent)\n",
        "        #im1 = ax1.imshow(test_img_list[i_img], extent=extent)\n",
        "        ax1.set_title(\"TEST_IMAGE_\"+str(i_img))\n",
        "        plt.colorbar(im1, ax=ax1, fraction=0.026, pad=0.04)\n",
        "        ax1.plot([0, N_set[0]],        [0, 0],               color='red', linestyle='solid')\n",
        "        ax1.plot([0, N_set[0]],        [N_set[1], N_set[1]], color='red', linestyle='solid')\n",
        "        ax1.plot([0, 0],               [0, N_set[1]],        color='red', linestyle='solid')\n",
        "        ax1.plot([N_set[0], N_set[0]], [0, N_set[1]],        color='red', linestyle='solid')\n",
        "\n",
        "    reward_map_temp = np.zeros((resol*N_set[0], resol*N_set[1]))\n",
        "    loss_test_img_temp = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(N_set[0]*N_set[1]*resol*resol):\n",
        "            i = idx//int(resol*N_set[1])\n",
        "            j = idx%int(resol*N_set[1])\n",
        "            phi_action = (i/(resol*N_set[0]))%1\n",
        "            theta_action = (j/(resol*N_set[1]))%1\n",
        "\n",
        "            state = test_img_data[i_img*resol*N_set[0]*N_set[1], :906]\n",
        "            actions = np.array([phi_action, theta_action, 0.1, 0.1])\n",
        "\n",
        "            input = torch.tensor(np.concatenate((state, actions))).float().to(device)\n",
        "            input = torch.unsqueeze(input, 0)\n",
        "            reward = model(input)\n",
        "            reward_map_temp[i, j] = reward\n",
        "        loss_test_img_temp += loss_fn(torch.tensor(reward_map_temp.T).cpu(), torch.tensor(test_img_list[i_img][:, :, 0])).item() # only valid if no extend\n",
        "    ax2.clear()\n",
        "    #im2 = ax2.imshow(reward_map_temp.T)#, vmin=-param[0], vmax=param[0])\n",
        "    im2 = ax2.imshow(reward_map_temp.T, vmin=-np.max(np.abs(reward_map_temp)), vmax=np.max(np.abs(reward_map_temp)))\n",
        "    ax2.set_title(\"MODEL_OUTPUT_\"+str(i_img)+\"(Loss=\"+str(int(1000*loss_test_img_temp)/1000)+\")\")\n",
        "    plt.colorbar(im2, ax=ax2, fraction=0.026, pad=0.04)\n",
        "\n",
        "    plt.show()\n",
        "    print(\"Test Img \"+str(i_img)+\" Loss = \"+str(int(1000*loss_test_img_temp)/1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1yGwp6IK5zo"
      },
      "source": [
        "### Data Preprocessing with Small Size Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTXZcDLp35Rv"
      },
      "outputs": [],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, x_tensor, y_tensor):\n",
        "        super(Dataset, self).__init__()\n",
        "\n",
        "        if not torch.is_tensor(x_tensor):\n",
        "            self.x = torch.tensor(x_tensor).float()\n",
        "            self.y = torch.tensor(y_tensor).float()\n",
        "        else:\n",
        "            self.x = x_tensor.float()\n",
        "            self.y = y_tensor.float()\n",
        "\n",
        "    def __getitem__(self, index): return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self): return self.x.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k7TzbP0b0hm"
      },
      "source": [
        "#### (src for showing reward map examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZktqRxVfu0Va",
        "outputId": "58e774f7-cc72-4f66-8cb6-c26e02be3616"
      },
      "outputs": [],
      "source": [
        "# seed\n",
        "seed = 722\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 1024\n",
        "learning_rate = 6e-5\n",
        "max_epoch = 1000\n",
        "\n",
        "# other parameters\n",
        "N_set = (40, 20)\n",
        "resol = 1\n",
        "\n",
        "map_modifier = RewardMapModifier(extends=(0, 0), blur_coef=(3, 2)) #if you use CNN, do not use extend method\n",
        "chunk_size = 256\n",
        "chunk_set_size = chunk_size*N_set[0]*N_set[1]\n",
        "online_dataset_path = \"/content/gdrive/MyDrive/Asteroid RL dataset/online_dataset/\"\n",
        "\n",
        "\n",
        "data_len2 = int(data_RL_preset2[0, 0])\n",
        "test_img_num = 10\n",
        "test_img_idx_choice = np.random.randint(0, (data_len2-1)//800, test_img_num)\n",
        "dataset_img_idx = np.full(data_len2, False)\n",
        "for i in test_img_idx_choice:\n",
        "    dataset_img_idx[i*800+1:(i+1)*800+1] = True\n",
        "\n",
        "print(\"test_img_idx (in RL_preset_batch_2) :\", test_img_idx_choice)\n",
        "print(\"--------------------------------\")\n",
        "print(\"\")\n",
        "\n",
        "data_RL_preset = data_RL_preset0[1:, :]\n",
        "test_img_data = data_RL_preset2[dataset_img_idx, :].copy()\n",
        "del data_RL_preset2\n",
        "gc.collect()\n",
        "\n",
        "test_img_list = []\n",
        "for i in range(test_img_num):\n",
        "    test_img_list.append(test_img_data[i*resol*N_set[0]*N_set[1]:(i+1)*resol*N_set[0]*N_set[1], -1].reshape((N_set[0], N_set[1])).T)\n",
        "\n",
        "for i in range(len(test_img_list)):\n",
        "    test_img_list[i], _ = map_modifier.operation(np.expand_dims(test_img_list[i], axis=-1), None, order=['extend_vert', 'extend_hori', 'blur'])\n",
        "    #test_img_list[i] = test_img_list[i][:, :, 0]\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "#cut = N_set[0]*N_set[1]*2093 + 1 #1040\n",
        "#state_data = data_RL_preset[:cut, :-5]\n",
        "#action_data = data_RL_preset[:cut, -5:-1]\n",
        "#reward_data = data_RL_preset[:cut, -1:]\n",
        "state_data = data_RL_preset[:, :-5]\n",
        "action_data = data_RL_preset[:, -5:-1]\n",
        "reward_data = data_RL_preset[:, -1:]\n",
        "\n",
        "\n",
        "new_action_data = 0 * np.array([action_data[0, ...].copy()])\n",
        "new_reward_data = 0 * np.array([reward_data[0, ...].copy()])\n",
        "\n",
        "print(\"Data Shapes Before Map Modifying\")\n",
        "print(\"--------------------------------\")\n",
        "print(\"state_data  | \"+str(state_data.shape)+\", \"+str(int(1000*state_data.itemsize*state_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"action_data | \"+str(action_data.shape)+\"  , \"+str(int(1000*action_data.itemsize*action_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"reward_data | \"+str(reward_data.shape)+\"  , \"+str(int(1000*reward_data.itemsize*reward_data.size/(2**30))/1000)+\"GB\")\n",
        "\n",
        "print(\"\\n--------------------------------\")\n",
        "for i in range(math.ceil(state_data.shape[0]/chunk_set_size)):\n",
        "    if i != state_data.shape[0]//(chunk_size*N_set[0]*N_set[1]):\n",
        "        reward_map = reward_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
        "        action_maps = action_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
        "    else:\n",
        "        reward_map = reward_data[chunk_set_size*i:]\n",
        "        action_maps = action_data[chunk_set_size*i:]\n",
        "\n",
        "    print(\"Batch Shape : reward / action | \"+str(reward_map.shape)+\", \"+str(action_maps.shape)+\" --> \", end='')\n",
        "    reward_map = np.swapaxes(reward_map.reshape((-1, N_set[0], N_set[1], 1)), -2, -3)\n",
        "    action_maps = np.swapaxes(action_maps.reshape((-1, N_set[0], N_set[1], 4)), -2, -3)\n",
        "    reward_map, action_maps = map_modifier.operation(reward_map, action_maps, order=['extend_vert', 'extend_hori', 'blur'])\n",
        "    print(str(reward_map.shape)+\", \"+str(action_maps.shape))\n",
        "\n",
        "    extended_size = reward_map.shape[-2] * reward_map.shape[-3]\n",
        "    new_action_data = np.concatenate((new_action_data, action_maps.reshape(-1, 4)), axis=0)\n",
        "    new_reward_data = np.concatenate((new_reward_data, reward_map.reshape(-1, 1)), axis=0)\n",
        "print(\"--------------------------------\\n\")\n",
        "\n",
        "state_data = np.repeat(state_data[::N_set[0]*N_set[1]], repeats=extended_size, axis=0)\n",
        "action_data = np.delete(new_action_data, 0, axis=0)\n",
        "reward_data = np.delete(new_reward_data, 0, axis=0)\n",
        "\n",
        "del new_action_data, new_reward_data, reward_map, action_maps\n",
        "del data_RL_preset, data_RL_preset0\n",
        "gc.collect()\n",
        "\n",
        "print(\"Data Shapes After Map Mpdifying\")\n",
        "print(\"--------------------------------\")\n",
        "print(\"state_data  | \"+str(state_data.shape)+\", \"+str(int(1000*state_data.itemsize*state_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"action_data | \"+str(action_data.shape)+\"  , \"+str(int(1000*action_data.itemsize*action_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"reward_data | \"+str(reward_data.shape)+\"  , \"+str(int(1000*reward_data.itemsize*reward_data.size/(2**30))/1000)+\"GB\")\n",
        "\n",
        "ext_N_set = map_modifier.ext_N_set(N_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X7-i8vvcL66v",
        "outputId": "abec9993-30eb-4571-a533-7ac2d1b74589"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 120, 30):\n",
        "    plt.imshow(reward_data[i*800:(i+1)*800, 0].reshape(20, 40))\n",
        "    plt.colorbar()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOWfAoplNqeE",
        "outputId": "8ed17136-29ad-4e91-87a2-e94fd2831b0d"
      },
      "outputs": [],
      "source": [
        "total_data = np.concatenate((state_data, action_data, reward_data), axis=1)\n",
        "state_shape = state_data.shape[1]\n",
        "del state_data, action_data, reward_data\n",
        "gc.collect()\n",
        "\n",
        "train_data, test_data = data_split(total_data, train_ratio=0.85, shuffle=True, copy=True)\n",
        "del total_data\n",
        "gc.collect()\n",
        "\n",
        "train_state_data = train_data[:, :state_shape].copy()\n",
        "train_action_data = train_data[:, state_shape:state_shape+4].copy()\n",
        "train_reward_data = train_data[:, -1].reshape(-1, 1)\n",
        "del train_data\n",
        "gc.collect()\n",
        "\n",
        "test_state_data = test_data[:, :state_shape].copy()\n",
        "test_action_data = test_data[:, state_shape:state_shape+4].copy()\n",
        "test_reward_data = test_data[:, -1].reshape(-1, 1)\n",
        "del test_data\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3luOZYEcBDo"
      },
      "source": [
        "#### (src for skipping showing reward map examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OFVzgiMgUc4D",
        "outputId": "86043abe-55ec-4004-e530-d85ab4468f4d"
      },
      "outputs": [],
      "source": [
        "# seed\n",
        "seed = 722\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 1024\n",
        "learning_rate = 6e-5\n",
        "max_epoch = 1000\n",
        "\n",
        "# other parameters\n",
        "N_set = (40, 20)\n",
        "resol = 1\n",
        "\n",
        "map_modifier = RewardMapModifier(extends=(0, 0), blur_coef=(3, 2)) #if you use CNN, do not use extend method\n",
        "chunk_size = 256\n",
        "chunk_set_size = chunk_size*N_set[0]*N_set[1]\n",
        "online_dataset_path = \"/content/gdrive/MyDrive/Asteroid RL dataset/online_dataset/\"\n",
        "\n",
        "\n",
        "data_len2 = int(data_RL_preset2[0, 0])\n",
        "test_img_num = 10\n",
        "test_img_idx_choice = np.random.randint(0, (data_len2-1)//800, test_img_num)\n",
        "dataset_img_idx = np.full(data_len2, False)\n",
        "for i in test_img_idx_choice:\n",
        "    dataset_img_idx[i*800+1:(i+1)*800+1] = True\n",
        "\n",
        "print(\"test_img_idx (in RL_preset_batch_2) :\", test_img_idx_choice)\n",
        "print(\"--------------------------------\")\n",
        "print(\"\")\n",
        "\n",
        "data_RL_preset = data_RL_preset0[1:, :]\n",
        "test_img_data = data_RL_preset2[dataset_img_idx, :].copy()\n",
        "del data_RL_preset2\n",
        "gc.collect()\n",
        "\n",
        "test_img_list = []\n",
        "for i in range(test_img_num):\n",
        "    test_img_list.append(test_img_data[i*resol*N_set[0]*N_set[1]:(i+1)*resol*N_set[0]*N_set[1], -1].reshape((N_set[0], N_set[1])).T)\n",
        "\n",
        "for i in range(len(test_img_list)):\n",
        "    test_img_list[i], _ = map_modifier.operation(np.expand_dims(test_img_list[i], axis=-1), None, order=['extend_vert', 'extend_hori', 'blur'])\n",
        "    #test_img_list[i] = test_img_list[i][:, :, 0]\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "#cut = N_set[0]*N_set[1]*2093 + 1 #1040\n",
        "#state_data = data_RL_preset[:cut, :-5]\n",
        "#action_data = data_RL_preset[:cut, -5:-1]\n",
        "#reward_data = data_RL_preset[:cut, -1:]\n",
        "state_data = data_RL_preset[:, :-5]\n",
        "action_data = data_RL_preset[:, -5:-1]\n",
        "reward_data = data_RL_preset[:, -1:]\n",
        "\n",
        "\n",
        "new_action_data = 0 * np.array([action_data[0, ...].copy()])\n",
        "new_reward_data = 0 * np.array([reward_data[0, ...].copy()])\n",
        "\n",
        "print(\"Data Shapes Before Map Modifying\")\n",
        "print(\"--------------------------------\")\n",
        "print(\"state_data  | \"+str(state_data.shape)+\", \"+str(int(1000*state_data.itemsize*state_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"action_data | \"+str(action_data.shape)+\"  , \"+str(int(1000*action_data.itemsize*action_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"reward_data | \"+str(reward_data.shape)+\"  , \"+str(int(1000*reward_data.itemsize*reward_data.size/(2**30))/1000)+\"GB\")\n",
        "\n",
        "print(\"\\n--------------------------------\")\n",
        "for i in range(math.ceil(state_data.shape[0]/chunk_set_size)):\n",
        "    if i != state_data.shape[0]//(chunk_size*N_set[0]*N_set[1]):\n",
        "        reward_map = reward_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
        "        action_maps = action_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
        "    else:\n",
        "        reward_map = reward_data[chunk_set_size*i:]\n",
        "        action_maps = action_data[chunk_set_size*i:]\n",
        "\n",
        "    print(\"Batch Shape : reward / action | \"+str(reward_map.shape)+\", \"+str(action_maps.shape)+\" --> \", end='')\n",
        "    reward_map = np.swapaxes(reward_map.reshape((-1, N_set[0], N_set[1], 1)), -2, -3)\n",
        "    action_maps = np.swapaxes(action_maps.reshape((-1, N_set[0], N_set[1], 4)), -2, -3)\n",
        "    reward_map, action_maps = map_modifier.operation(reward_map, action_maps, order=['extend_vert', 'extend_hori', 'blur'])\n",
        "    print(str(reward_map.shape)+\", \"+str(action_maps.shape))\n",
        "\n",
        "    extended_size = reward_map.shape[-2] * reward_map.shape[-3]\n",
        "    new_action_data = np.concatenate((new_action_data, action_maps.reshape(-1, 4)), axis=0)\n",
        "    new_reward_data = np.concatenate((new_reward_data, reward_map.reshape(-1, 1)), axis=0)\n",
        "print(\"--------------------------------\\n\")\n",
        "\n",
        "state_data = np.repeat(state_data[::N_set[0]*N_set[1]], repeats=extended_size, axis=0)\n",
        "action_data = np.delete(new_action_data, 0, axis=0)\n",
        "reward_data = np.delete(new_reward_data, 0, axis=0)\n",
        "\n",
        "del new_action_data, new_reward_data, reward_map, action_maps\n",
        "del data_RL_preset, data_RL_preset0\n",
        "gc.collect()\n",
        "\n",
        "print(\"Data Shapes After Map Mpdifying\")\n",
        "print(\"--------------------------------\")\n",
        "print(\"state_data  | \"+str(state_data.shape)+\", \"+str(int(1000*state_data.itemsize*state_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"action_data | \"+str(action_data.shape)+\"  , \"+str(int(1000*action_data.itemsize*action_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"reward_data | \"+str(reward_data.shape)+\"  , \"+str(int(1000*reward_data.itemsize*reward_data.size/(2**30))/1000)+\"GB\")\n",
        "\n",
        "ext_N_set = map_modifier.ext_N_set(N_set)\n",
        "\n",
        "\n",
        "total_data = np.concatenate((state_data.reshape(-1, ext_N_set[0]*ext_N_set[1], state_data.shape[-1]),\n",
        "                             action_data.reshape(-1, ext_N_set[0]*ext_N_set[1], action_data.shape[-1]),\n",
        "                             reward_data.reshape(-1, ext_N_set[0]*ext_N_set[1], reward_data.shape[-1])), axis=-1)\n",
        "state_shape = state_data.shape[1]\n",
        "del state_data, action_data, reward_data\n",
        "gc.collect()\n",
        "\n",
        "train_data, test_data = data_split(total_data, train_ratio=0.85, shuffle=True, copy=True)\n",
        "del total_data\n",
        "gc.collect()\n",
        "\n",
        "train_data = train_data.reshape(-1, state_shape+4+1)\n",
        "test_data = test_data.reshape(-1, state_shape+4+1)\n",
        "\n",
        "train_state_data = train_data[:, :state_shape].copy()\n",
        "train_action_data = train_data[:, state_shape:state_shape+4].copy()\n",
        "train_reward_data = train_data[:, -1].reshape(-1, 1)\n",
        "del train_data\n",
        "gc.collect()\n",
        "\n",
        "test_state_data = test_data[:, :state_shape].copy()\n",
        "test_action_data = test_data[:, state_shape:state_shape+4].copy()\n",
        "test_reward_data = test_data[:, -1].reshape(-1, 1)\n",
        "del test_data\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUxxexjYprep"
      },
      "source": [
        "#### Use data_RL_preset2 as Testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3sc_eOe8pqfo",
        "outputId": "f1871ff7-2ecf-46fa-dba4-d17430550e93"
      },
      "outputs": [],
      "source": [
        "# seed\n",
        "seed = 722\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 1024\n",
        "learning_rate = 6e-5\n",
        "max_epoch = 1000\n",
        "\n",
        "# other parameters\n",
        "N_set = (40, 20)\n",
        "resol = 1\n",
        "\n",
        "map_modifier = RewardMapModifier(extends=(0, 0), blur_coef=(3, 2)) #if you use CNN, do not use extend method\n",
        "chunk_size = 256\n",
        "chunk_set_size = chunk_size*N_set[0]*N_set[1]\n",
        "online_dataset_path = \"/content/gdrive/MyDrive/Asteroid RL dataset/online_dataset/\"\n",
        "\n",
        "\n",
        "data_len2 = int(data_RL_preset2[0, 0])\n",
        "test_img_num = 10\n",
        "test_img_idx_choice = np.random.randint(0, (data_len2-1)//800, test_img_num)\n",
        "dataset_img_idx = np.full(data_len2, False)\n",
        "for i in test_img_idx_choice:\n",
        "    dataset_img_idx[i*800+1:(i+1)*800+1] = True\n",
        "\n",
        "print(\"test_img_idx (in RL_preset_batch_2) :\", test_img_idx_choice)\n",
        "print(\"--------------------------------\")\n",
        "print(\"\")\n",
        "\n",
        "data_RL_preset = data_RL_preset0[1:, :]\n",
        "test_img_data = data_RL_preset2[dataset_img_idx, :].copy()\n",
        "del data_RL_preset2\n",
        "gc.collect()\n",
        "\n",
        "test_img_list = []\n",
        "for i in range(test_img_num):\n",
        "    test_img_list.append(test_img_data[i*resol*N_set[0]*N_set[1]:(i+1)*resol*N_set[0]*N_set[1], -1].reshape((N_set[0], N_set[1])).T)\n",
        "\n",
        "for i in range(len(test_img_list)):\n",
        "    test_img_list[i], _ = map_modifier.operation(np.expand_dims(test_img_list[i], axis=-1), None, order=['extend_vert', 'extend_hori', 'blur'])\n",
        "    #test_img_list[i] = test_img_list[i][:, :, 0]\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "#cut = N_set[0]*N_set[1]*2093 + 1 #1040\n",
        "#state_data = data_RL_preset[:cut, :-5]\n",
        "#action_data = data_RL_preset[:cut, -5:-1]\n",
        "#reward_data = data_RL_preset[:cut, -1:]\n",
        "state_data = data_RL_preset[:, :-5]\n",
        "action_data = data_RL_preset[:, -5:-1]\n",
        "reward_data = data_RL_preset[:, -1:]\n",
        "\n",
        "\n",
        "new_action_data = 0 * np.array([action_data[0, ...].copy()])\n",
        "new_reward_data = 0 * np.array([reward_data[0, ...].copy()])\n",
        "\n",
        "print(\"Data Shapes Before Map Modifying\")\n",
        "print(\"--------------------------------\")\n",
        "print(\"state_data  | \"+str(state_data.shape)+\", \"+str(int(1000*state_data.itemsize*state_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"action_data | \"+str(action_data.shape)+\"  , \"+str(int(1000*action_data.itemsize*action_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"reward_data | \"+str(reward_data.shape)+\"  , \"+str(int(1000*reward_data.itemsize*reward_data.size/(2**30))/1000)+\"GB\")\n",
        "\n",
        "print(\"\\n--------------------------------\")\n",
        "for i in range(math.ceil(state_data.shape[0]/chunk_set_size)):\n",
        "    if i != state_data.shape[0]//(chunk_size*N_set[0]*N_set[1]):\n",
        "        reward_map = reward_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
        "        action_maps = action_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
        "    else:\n",
        "        reward_map = reward_data[chunk_set_size*i:]\n",
        "        action_maps = action_data[chunk_set_size*i:]\n",
        "\n",
        "    print(\"Batch Shape : reward / action | \"+str(reward_map.shape)+\", \"+str(action_maps.shape)+\" --> \", end='')\n",
        "    reward_map = np.swapaxes(reward_map.reshape((-1, N_set[0], N_set[1], 1)), -2, -3)\n",
        "    action_maps = np.swapaxes(action_maps.reshape((-1, N_set[0], N_set[1], 4)), -2, -3)\n",
        "    reward_map, action_maps = map_modifier.operation(reward_map, action_maps, order=['extend_vert', 'extend_hori', 'blur'])\n",
        "    print(str(reward_map.shape)+\", \"+str(action_maps.shape))\n",
        "\n",
        "    extended_size = reward_map.shape[-2] * reward_map.shape[-3]\n",
        "    new_action_data = np.concatenate((new_action_data, action_maps.reshape(-1, 4)), axis=0)\n",
        "    new_reward_data = np.concatenate((new_reward_data, reward_map.reshape(-1, 1)), axis=0)\n",
        "print(\"--------------------------------\\n\")\n",
        "\n",
        "state_data = np.repeat(state_data[::N_set[0]*N_set[1]], repeats=extended_size, axis=0)\n",
        "action_data = np.delete(new_action_data, 0, axis=0)\n",
        "reward_data = np.delete(new_reward_data, 0, axis=0)\n",
        "\n",
        "del new_action_data, new_reward_data, reward_map, action_maps\n",
        "del data_RL_preset, data_RL_preset0\n",
        "gc.collect()\n",
        "\n",
        "print(\"Data Shapes After Map Mpdifying\")\n",
        "print(\"--------------------------------\")\n",
        "print(\"state_data  | \"+str(state_data.shape)+\", \"+str(int(1000*state_data.itemsize*state_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"action_data | \"+str(action_data.shape)+\"  , \"+str(int(1000*action_data.itemsize*action_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"reward_data | \"+str(reward_data.shape)+\"  , \"+str(int(1000*reward_data.itemsize*reward_data.size/(2**30))/1000)+\"GB\")\n",
        "\n",
        "ext_N_set = map_modifier.ext_N_set(N_set)\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Shifted Data Generation\n",
        "# ------------------------------\n",
        "shift_unit = 1 #1 is minimum unit --> most data generation (20 times)\n",
        "new_state_data = state_data.reshape(-1, 800, state_shape)\n",
        "new_action_data = action_data.reshape(-1, 800, 4)\n",
        "new_reward_data = np.swapaxes(reward_data.reshape(-1, 800, 40, 20), 2, 3)\n",
        "\n",
        "original_data_img_num = new_state_data.shape[0] + 0\n",
        "\n",
        "new_state_data = np.tile(new_state_data, (20//shift_unit, 1, 1))\n",
        "new_action_data = np.tile(new_action_data, (20//shift_unit, 1, 1))\n",
        "new_reward_data = np.tile(new_reward_data, (20//shift_unit, 1, 1, 1))\n",
        "for i in range(1, 20//shift_unit+1):\n",
        "    new_state_data[i*original_data_img_num:(i+1)*original_data_img_num, :, 800:900] = np.roll(new_state_data[i*original_data_img_num:(i+1)*original, :, 800:900], 5*shift_unit, axis=-1)\n",
        "    new_reward_data[i*original_data_img_num:(i+1)*original_data_img_num, :, :, :] = np.roll(ew_reward_data[i*original_data_img_num:(i+1)*original_data_img_num, :, :, :], 2*shift_unit, axis=-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "total_data = np.concatenate((state_data, action_data, reward_data), axis=-1)\n",
        "state_shape = state_data.shape[1]\n",
        "del state_data, action_data, reward_data\n",
        "gc.collect()\n",
        "\n",
        "train_data, test_data = data_split(total_data, train_ratio=0.85, shuffle=True, copy=True)\n",
        "del total_data, test_data\n",
        "gc.collect()\n",
        "\n",
        "train_data = train_data.reshape(-1, state_shape+4+1)\n",
        "\n",
        "train_state_data = train_data[:, :state_shape].copy()\n",
        "train_action_data = train_data[:, state_shape:state_shape+4].copy()\n",
        "train_reward_data = train_data[:, -1].reshape(-1, 1)\n",
        "del train_data\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "t84_U22NqcvT",
        "outputId": "1364bd21-4410-47f0-a97f-b6da2a9e7962"
      },
      "outputs": [],
      "source": [
        "test_data = test_img_data.copy()\n",
        "print(\"\\n\"+(\"-\"*20))\n",
        "print(\"Test Data Shape : \"+str(test_data.shape))\n",
        "\n",
        "test_state_data = test_data[:, :state_shape].copy()\n",
        "test_action_data = test_data[:, state_shape:state_shape+4].copy()\n",
        "test_reward_data = np.swapaxes(test_data[:, -1].reshape(-1, 40, 20, 1), -2, -3)\n",
        "test_reward_data, _ = map_modifier.operation(test_reward_data, None, order=['extend_vert', 'extend_hori', 'blur'])\n",
        "test_reward_data = np.swapaxes(test_reward_data, -2, -3).reshape(-1, 1)\n",
        "\n",
        "del test_data\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGDD5gcApwCh"
      },
      "source": [
        "#### to Dataset class for pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DiUZDX_9kOV2",
        "outputId": "96160899-d0fd-4db8-a365-3e9a0238b40c"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(np.concatenate((train_state_data, train_action_data), axis=1), train_reward_data)\n",
        "test_dataset = Dataset(np.concatenate((test_state_data, test_action_data), axis=1), test_reward_data)\n",
        "\n",
        "train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = data.DataLoader(dataset=test_dataset, batch_size=800, shuffle=False)\n",
        "\n",
        "del train_state_data, train_action_data, train_reward_data\n",
        "del test_state_data, test_action_data, test_reward_data\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBqbzM47LGZE"
      },
      "source": [
        "### Data Preprocessing with Large Size Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqA1U3B_WapJ"
      },
      "outputs": [],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, x_tensor, y_tensor, chunk_size=None, online_dataset_path=None, usage=None, N_set=(40, 20), train_ratio=0.7):\n",
        "        super(Dataset, self).__init__()\n",
        "\n",
        "        # x_tensor is used as (ndarray)data path list\n",
        "        # it includes y_data --> delete after loading\n",
        "\n",
        "        self.chunk_list = x_tensor\n",
        "        self.y = y_tensor\n",
        "\n",
        "        self.chunk_size = chunk_size\n",
        "        self.online_dataset_path = online_dataset_path\n",
        "        self.usage = usage\n",
        "        self.N_set = N_set\n",
        "        self.train_ratio = train_ratio\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        chunk_len = int(self.train_ratio*self.chunk_size*self.N_set[0]*self.N_set[1])\n",
        "        if self.usage == 'test':\n",
        "            chunk_len = self.chunk_size*self.N_set[0]*self.N_set[1] - chunk_len\n",
        "        chunk_idx = index//chunk_len\n",
        "        chunk = np.load(self.online_dataset_path+self.usage+\"_chunk_\"+str(chunk_idx)+\".npz\",)\n",
        "        x = chunk['x'][index%chunk_len]\n",
        "        x = torch.from_numpy(x).float()\n",
        "        y = torch.from_numpy(self.y[index]).float()\n",
        "\n",
        "        del chunk\n",
        "        gc.collect()\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self): return self.y.shape[0]\n",
        "\n",
        "\n",
        "def generate_dataset(datasets, online_dataset_path, map_modifier, chunk_size, starting_idx=0, train_ratio=0.7, shuffle=True, N_set=(40, 20)):\n",
        "    # Setting\n",
        "    state_data = datasets[0]\n",
        "    action_data = datasets[1]\n",
        "    reward_data = datasets[2]\n",
        "\n",
        "    chunk_set_size = chunk_size*N_set[0]*N_set[1]\n",
        "    train_chunk_list = []\n",
        "    test_chunk_list = []\n",
        "    train_y = np.array([reward_data[0, ...].copy()])\n",
        "    test_y = np.array([reward_data[0, ...].copy()])\n",
        "\n",
        "    for i in range(math.ceil(state_data.shape[0]/chunk_set_size)):\n",
        "        # Map Modifying\n",
        "        if i != state_data.shape[0]//chunk_set_size:\n",
        "            reward_map = reward_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
        "            action_maps = action_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
        "        else:\n",
        "            reward_map = reward_data[chunk_set_size*i:]\n",
        "            action_maps = action_data[chunk_set_size*i:]\n",
        "\n",
        "        print(\"\\n--------------------------------\")\n",
        "        print(\"Data Shape : reward / action | \"+str(reward_map.shape)+\", \"+str(action_maps.shape)+\" --> \", end='')\n",
        "\n",
        "        reward_map = np.swapaxes(reward_map.reshape((-1, N_set[0], N_set[1], 1)), -2, -3)\n",
        "        action_maps = np.swapaxes(action_maps.reshape((-1, N_set[0], N_set[1], 4)), -2, -3)\n",
        "        reward_map, action_maps = map_modifier.operation(reward_map, action_maps, order=['extend_hori', 'extend_vert', 'blur'])\n",
        "\n",
        "        print(str(reward_map.shape)+\", \"+str(action_maps.shape))\n",
        "\n",
        "        extended_size = reward_map.shape[-2] * reward_map.shape[-3]\n",
        "        chunk_reward_data = reward_map.reshape(-1, 1)\n",
        "        chunk_action_data = action_maps.reshape(-1, 4)\n",
        "        if i != state_data.shape[0]//chunk_set_size:\n",
        "            chunk_state_data = np.repeat(state_data[chunk_set_size*i:chunk_set_size*(i+1):N_set[0]*N_set[1]], repeats=extended_size, axis=0)\n",
        "        else:\n",
        "            chunk_state_data = np.repeat(state_data[chunk_set_size*i::N_set[0]*N_set[1]], repeats=extended_size, axis=0)\n",
        "\n",
        "        del reward_map, action_maps\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "        # Generate Dataset for working on Pytorch\n",
        "        total_data = np.concatenate((chunk_state_data, chunk_action_data, chunk_reward_data), axis=1)\n",
        "        state_shape = chunk_state_data.shape[1]\n",
        "        del chunk_state_data, chunk_action_data, chunk_reward_data\n",
        "        gc.collect()\n",
        "\n",
        "        chunk_train_data, chunk_test_data = data_split(total_data, train_ratio=train_ratio, shuffle=shuffle)\n",
        "\n",
        "        chunk_train_state_data = chunk_train_data[:, :state_shape]\n",
        "        chunk_train_action_data = chunk_train_data[:, state_shape:state_shape+4]\n",
        "        chunk_train_reward_data = chunk_train_data[:, -1].reshape(-1, 1)\n",
        "\n",
        "        chunk_test_state_data = chunk_test_data[:, :state_shape]\n",
        "        chunk_test_action_data = chunk_test_data[:, state_shape:state_shape+4]\n",
        "        chunk_test_reward_data = chunk_test_data[:, -1].reshape(-1, 1)\n",
        "\n",
        "        np.savez_compressed(online_dataset_path+\"train_chunk_\"+str(i+starting_idx)+\".npz\",\n",
        "                            x = np.concatenate((chunk_train_state_data, chunk_train_action_data), axis=1))\n",
        "                            #y = chunk_train_reward_data)\n",
        "        np.savez_compressed(online_dataset_path+\"test_chunk_\"+str(i+starting_idx)+\".npz\",\n",
        "                            x = np.concatenate((chunk_test_state_data, chunk_test_action_data), axis=1))\n",
        "                            #y = chunk_test_reward_data)\n",
        "\n",
        "        print(\"File Generated : train_chunk_\"+str(i+starting_idx), end='')\n",
        "        print(\" | Size : \"+str(int(1000*chunk_train_state_data.itemsize*(chunk_train_state_data.size+chunk_train_action_data.size+chunk_train_reward_data.size)/(2**30))/1000)+\"GB\")\n",
        "        print(\"File Generated : test_chunk_\"+str(i+starting_idx), end='')\n",
        "        print(\" | Size : \"+str(int(1000*chunk_test_state_data.itemsize*(chunk_test_state_data.size+chunk_test_action_data.size+chunk_test_reward_data.size)/(2**30))/1000)+\"GB\")\n",
        "\n",
        "        train_y = np.concatenate((train_y, chunk_train_reward_data), axis=0)\n",
        "        test_y = np.concatenate((test_y, chunk_test_reward_data), axis=0)\n",
        "\n",
        "        del total_data, chunk_train_data, chunk_test_data\n",
        "        del chunk_train_state_data, chunk_train_action_data, chunk_train_reward_data\n",
        "        del chunk_test_state_data, chunk_test_action_data, chunk_test_reward_data\n",
        "        gc.collect()\n",
        "\n",
        "        train_chunk_list.append(online_dataset_path+\"train_chunk_\"+str(i+starting_idx)+\".npz\")\n",
        "        test_chunk_list.append(online_dataset_path+\"test_chunk_\"+str(i+starting_idx)+\".npz\")\n",
        "\n",
        "    train_y = np.delete(train_y, 0, 0)\n",
        "    test_y = np.delete(test_y, 0, 0)\n",
        "\n",
        "    print(\"\\n--------------------------------\")\n",
        "    print(\"File Generated : train_y_from\"+str(starting_idx), end='')\n",
        "    print(\" | Size : \"+str(int(1000*train_y.itemsize*train_y.size/(2**30))/1000)+\"GB\")\n",
        "    print(\"File Generated : test_y_from\"+str(starting_idx), end='')\n",
        "    print(\" | Size : \"+str(int(1000*test_y.itemsize*test_y.size/(2**30))/1000)+\"GB\")\n",
        "\n",
        "    print(\"\\n[Generation Finished]\")\n",
        "    return train_chunk_list, train_y, test_chunk_list, test_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMz4TSVCJkn-"
      },
      "outputs": [],
      "source": [
        "# seed\n",
        "seed = 722\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 256\n",
        "learning_rate = 6e-5\n",
        "max_epoch = 1000\n",
        "\n",
        "# other parameters\n",
        "N_set = (40, 20)\n",
        "resol = 1\n",
        "\n",
        "# info about generating online datasets\n",
        "map_modifier = RewardMapModifier(extends=(0, 1), blur_coef=0)\n",
        "chunk_size = 256\n",
        "online_dataset_path = \"/content/gdrive/MyDrive/Asteroid RL dataset/online_dataset/\"\n",
        "starting_idx = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oQJ2MJYKnuQ",
        "outputId": "66e693b9-b9eb-425b-b869-27af63cf6ebc"
      },
      "outputs": [],
      "source": [
        "# Data Generation\n",
        "data_RL_preset0[1:, -1:] = scale_reward(data_RL_preset0[1:, -1:])\n",
        "\n",
        "data_len = data_RL_preset0[0, 0]\n",
        "test_img_data = data_RL_preset0[-int(data_RL_preset0[0, 1]):, :]\n",
        "test_img_num = int(data_RL_preset0[0, 1]/(resol*N_set[0]*N_set[1]))\n",
        "test_img_list = []\n",
        "for i in range(test_img_num):\n",
        "    test_img_list.append(test_img_data[i*resol*N_set[0]*N_set[1]:(i+1)*resol*N_set[0]*N_set[1], -1].reshape((N_set[0], N_set[1])).T)\n",
        "\n",
        "for i in range(len(test_img_list)):\n",
        "    test_img_list[i], _ = map_modifier.operation(np.expand_dims(test_img_list[i], axis=-1), None, order=['extend_hori', 'extend_vert', 'blur'])\n",
        "    test_img_list[i] = test_img_list[i][:, :, 0]\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "data_RL_preset = data_RL_preset0[1:-int(data_RL_preset0[0, 1]), :]\n",
        "state_data = data_RL_preset[:, :-5]\n",
        "action_data = data_RL_preset[:, -5:-1]\n",
        "reward_data = data_RL_preset[:, -1:]\n",
        "\n",
        "train_data_list, train_y, test_data_list, test_y = generate_dataset(datasets = (state_data, action_data, reward_data),\n",
        "                                                                    online_dataset_path = online_dataset_path,\n",
        "                                                                    map_modifier = map_modifier,\n",
        "                                                                    chunk_size = chunk_size,\n",
        "                                                                    starting_idx = starting_idx,\n",
        "                                                                    train_ratio = 0.7,\n",
        "                                                                    shuffle = True,\n",
        "                                                                    N_set = N_set)\n",
        "del data_RL_preset, data_RL_preset0\n",
        "del state_data, action_data, reward_data\n",
        "gc.collect()\n",
        "\n",
        "np.save(online_dataset_path+\"train_y_from\"+str(starting_idx)+\".npy\", train_y)\n",
        "np.save(online_dataset_path+\"test_y_from\"+str(starting_idx)+\".npy\", test_y)\n",
        "\n",
        "ext_N_set = map_modifier.ext_N_set(N_set)\n",
        "train_dataset = Dataset(train_data_list, train_y, chunk_size=chunk_size, online_dataset_path=online_dataset_path, usage='train', N_set=ext_N_set, train_ratio=0.7)\n",
        "test_dataset = Dataset(test_data_list, test_y, chunk_size=chunk_size, online_dataset_path=online_dataset_path, usage='test', N_set=ext_N_set, train_ratio=0.7)\n",
        "\n",
        "train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGpH7y0oIeqH"
      },
      "outputs": [],
      "source": [
        "online_data_list = os.listdir(online_dataset_path)\n",
        "train_data_list = [file for file in online_data_list if 'train_chunk' in file]\n",
        "test_data_list = [file for file in online_data_list if 'test_chunk' in file]\n",
        "ext_N_set = map_modifier.ext_N_set(N_set)\n",
        "\n",
        "train_dataset = Dataset(train_data_list, train_y, mode='online_dataset', chunk_size=chunk_size, online_dataset_path=online_dataset_path, usage='train', N_set=ext_N_set, train_ratio=0.7)\n",
        "test_dataset = Dataset(test_data_list, test_y, mode='online_dataset', chunk_size=chunk_size, online_dataset_path=online_dataset_path, usage='test', N_set=ext_N_set, train_ratio=0.7)\n",
        "\n",
        "train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aflVBgn-dyi0",
        "outputId": "a396fb5a-2864-46b9-8cb9-9d58c9e12842"
      },
      "outputs": [],
      "source": [
        "print(reward_data)\n",
        "print(np.max(reward_data))\n",
        "data_RL_preset0[0, 2] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-DFgTv_jxiG",
        "outputId": "a187a0ae-c28a-4b28-de0d-ef479e3163b0"
      },
      "outputs": [],
      "source": [
        "online_data_list = os.listdir(online_dataset_path)\n",
        "train_data_list = [file for file in online_data_list if 'train_chunk' in file]\n",
        "test_data_list = [file for file in online_data_list if 'test_chunk' in file]\n",
        "print(train_data_list)\n",
        "print(test_data_list)\n",
        "print()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIXXY-Wo2vfh"
      },
      "source": [
        "## **Training Part**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 28281
        },
        "id": "_hWQJ5WA1Akr",
        "outputId": "737b6f5b-beb3-45a6-a96b-34731d3cab03"
      },
      "outputs": [],
      "source": [
        "# hyperparameters blur\n",
        "learning_rate = 8e-5\n",
        "max_epoch = 200\n",
        "print(torch.__file__)\n",
        "\n",
        "model = QValueNet_CNN(input_dim=910, hidden_dim=1024, activation=nn.ELU, dropout=0.15).to(device)\n",
        "summary(model, (1, model.input_dim))\n",
        "\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "#loss_fn = CustomLoss(relative=False, percent=False)\n",
        "#loss_fn = CustomLoss1()\n",
        "loss_fn = CustomLoss2()\n",
        "\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "es = EarlyStopping(patience=2000, delta=0.1)\n",
        "for epoch in tqdm(range(max_epoch)):\n",
        "    #print(\"EPOCH \"+str(epoch)+\" TRAINING...\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer, train_loss, es)\n",
        "    #print(\"EPOCH \"+str(epoch)+\" TESTING...\")\n",
        "    test_loop(test_dataloader, model, loss_fn, test_loss, epoch)\n",
        "    #print(\"\")\n",
        "\n",
        "    if es.early_stop:\n",
        "        print(\"EarlyStop Triggered : Bestscore = {:7.4g}\".format(es.best_score))\n",
        "        break\n",
        "\n",
        "    if (epoch+1)%10 == 0 and epoch != 0:\n",
        "        plt.figure(figsize=(8, 6), dpi=300)\n",
        "        plt.plot(train_loss[2:], label='train_loss')\n",
        "        plt.plot(test_loss[2:], label='test_loss')\n",
        "        plt.legend()\n",
        "        plt.title(\"Train/Test Loss (MSE)\")\n",
        "        plt.show()\n",
        "\n",
        "        for i in range(test_img_num):\n",
        "            #if (i > 3 and i < 15) or i > 19:\n",
        "            #    continue\n",
        "            test_img_show(i, loss_fn)\n",
        "\n",
        "        PATH = str(epoch+1)+\"model.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'test_loss': test_loss,\n",
        "        }, PATH)\n",
        "\n",
        "    print(\"[epochs:{:2}]\".format(epoch+2), end='')\n",
        "\n",
        "print(\"DONE\")\n",
        "\n",
        "plt.figure(dpi=300)\n",
        "plt.plot(train_loss[2:], label='train_loss')\n",
        "plt.plot(test_loss[2:], label='test_loss')\n",
        "plt.legend()\n",
        "plt.title(\"Train/Test Loss (MSE)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj7vM1a-1PIW"
      },
      "source": [
        "save no-scaling result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZe9yhiclWGs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcQSSLJ8nPBO"
      },
      "outputs": [],
      "source": [
        "save_epoch = 179\n",
        "PATH = str(save_epoch)+\"model.pt\"\n",
        "\n",
        "torch.save({\n",
        "    'epoch': save_epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'train_loss': train_loss,\n",
        "    'test_loss': test_loss,\n",
        "}, PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BFdDb36oUjo"
      },
      "source": [
        "Train Continuing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PzGjxD3eoT1I",
        "outputId": "c44bee34-8c6c-4497-ba72-b8c264144632"
      },
      "outputs": [],
      "source": [
        "save_epoch = 162\n",
        "PATH = str(save_epoch)+\"model.pt\"\n",
        "\n",
        "# hyperparameters\n",
        "learning_rate = 8e-5\n",
        "max_epoch = 400\n",
        "print(torch.__file__)\n",
        "\n",
        "model = QValueNet_CNN(input_dim=910, hidden_dim=1024, activation=nn.ELU, dropout=0.15).to(device)\n",
        "summary(model, (1, model.input_dim))\n",
        "\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "loss_fn = CustomLoss(relative=False, percent=False)\n",
        "\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch0 = checkpoint['epoch']\n",
        "train_loss = checkpoint['train_loss']\n",
        "test_loss = checkpoint['test_loss']\n",
        "\n",
        "es = EarlyStopping(patience=2000, delta=0.1)\n",
        "for epoch in tqdm(range(epoch0+1, max_epoch)):\n",
        "    #print(\"EPOCH \"+str(epoch)+\" TRAINING...\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer, train_loss, es)\n",
        "    #print(\"EPOCH \"+str(epoch)+\" TESTING...\")\n",
        "    test_loop(test_dataloader, model, loss_fn, test_loss, epoch)\n",
        "    #print(\"\")\n",
        "\n",
        "    if es.early_stop:\n",
        "        print(\"EarlyStop Triggered : Bestscore = {:7.4g}\".format(es.best_score))\n",
        "        break\n",
        "\n",
        "    if (epoch+1)%10 == 0 and epoch != 0:\n",
        "        plt.figure(figsize=(8, 6), dpi=300)\n",
        "        plt.plot(train_loss[2:], label='train_loss')\n",
        "        plt.plot(test_loss[2:], label='test_loss')\n",
        "        plt.legend()\n",
        "        plt.title(\"Train/Test Loss (MSE)\")\n",
        "        plt.show()\n",
        "\n",
        "        for i in range(test_img_num):\n",
        "            #if (i > 3 and i < 15) or i > 19:\n",
        "            #    continue\n",
        "            test_img_show(i)\n",
        "\n",
        "    print(\"[epochs:{:2}]\".format(epoch+2), end='')\n",
        "\n",
        "print(\"DONE\")\n",
        "\n",
        "plt.figure(dpi=300)\n",
        "plt.plot(train_loss[2:], label='train_loss')\n",
        "plt.plot(test_loss[2:], label='test_loss')\n",
        "plt.legend()\n",
        "plt.title(\"Train/Test Loss (MSE)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aia9b3dCWeQ0"
      },
      "outputs": [],
      "source": [
        "for i in range(test_img_num):\n",
        "    test_img_show(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyACgjD5P-ml"
      },
      "source": [
        "# **Training with Classification Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36EALrTgPkMW"
      },
      "outputs": [],
      "source": [
        "class QValueClassifierNet_CNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=512, output_dim=3, activation=nn.ReLU, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.activation = activation\n",
        "\n",
        "        # R_arr encoders (input: [B, C, 40, 20])\n",
        "        self.r_arr_encoder1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 9),  # 1 channel / assumed input is already done padding=1 #(1, 16, 3)\n",
        "            self.activation(),\n",
        "            nn.MaxPool2d(2)  # -> 20×10\n",
        "        )\n",
        "\n",
        "        self.r_arr_encoder2 = nn.Sequential(\n",
        "            nn.Conv2d(8, 16, 5),  # assumed input is already done padding=1 #(16, 32, 3)\n",
        "            self.activation(),\n",
        "            nn.Flatten(),     # -> 16×20×10 = 3200  # -> 32×20×10 = 6400\n",
        "            nn.Linear(3200, 1024)\n",
        "        )\n",
        "\n",
        "        # Info encoder (input: [B, 1, 6])\n",
        "        self.info_encoder = nn.Sequential(\n",
        "            nn.Linear(6, 32),\n",
        "            self.activation(),\n",
        "            nn.Linear(32, 64)\n",
        "        )\n",
        "\n",
        "        # RL encoder (input: [B, 1, 4])\n",
        "        self.rl_encoder = nn.Sequential(\n",
        "            nn.Linear(4, 32),\n",
        "            self.activation(),\n",
        "            nn.Linear(32, 64)\n",
        "        )\n",
        "\n",
        "        # Lightcurves encoder (input: [B, 1, 100])\n",
        "        self.lc_encoder1 = nn.Sequential(\n",
        "            nn.Conv1d(1, 16, kernel_size=15),\n",
        "            self.activation(),\n",
        "            nn.MaxPool1d(2),   # → 50\n",
        "        )\n",
        "\n",
        "        self.lc_encoder2 = nn.Sequential(\n",
        "            nn.Conv1d(16, 32, kernel_size=9),\n",
        "            self.activation(),\n",
        "            nn.Flatten(),      # → 32×50\n",
        "            nn.Linear(32*50, 256)\n",
        "        )\n",
        "\n",
        "        # Fusion & Head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(1024 + 256 + 64 + 64, 1024),\n",
        "            self.activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(1024, 256),\n",
        "            self.activation(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Linear(256, self.output_dim)  # e.g., class count or regression value\n",
        "        )\n",
        "\n",
        "    def r_padding(self, x, pad=(1, 1)):\n",
        "        N, C, H, W = x.shape\n",
        "        pad_H = pad[0]\n",
        "        pad_W = pad[1]\n",
        "\n",
        "        out = torch.full((N, C, H + 2*pad_H, W + 2*pad_W), fill_value=0.0, dtype=x.dtype, device=x.device)\n",
        "        out[:, :, pad_H:pad_H+H, pad_W:pad_W+W] = x\n",
        "        out[:, :, :, :pad_W] = torch.roll(torch.flip(out[:, :, :, pad_W:pad_W+pad_W], (-2,)), 20, -1)\n",
        "        out[:, :, :, -pad_W:] = torch.roll(torch.flip(out[:, :, :, -pad_W-pad_W:-pad_W], (-2,)), 20, -1)\n",
        "        out[:, :, :pad_H, pad_W:pad_W+W] = x[:, :, -pad_H:, :]\n",
        "        out[:, :, -pad_H:, pad_W:pad_W+W] = x[:, :, :pad_H, :]\n",
        "        return out\n",
        "\n",
        "    def lc_padding(self, x, pad=1):\n",
        "        N, C, W = x.shape\n",
        "\n",
        "        out = torch.full((N, C, W + 2*pad), fill_value=0.0, dtype=x.dtype, device=x.device)\n",
        "        out[:, :, pad:pad+W] = x\n",
        "        out[:, :, :pad] = x[:, :, -pad:]\n",
        "        out[:, :, -pad:] = x[:, :, :pad]\n",
        "        return out\n",
        "\n",
        "    def forward(self, X):\n",
        "        r_arr = X[..., :800].reshape((X.shape[0], 1, 40, 20))\n",
        "        lc_arr = X[..., 800:900].reshape((X.shape[0], 1, 100))\n",
        "        lc_info = X[..., 900:906]\n",
        "        rl_info = X[..., 906:]\n",
        "\n",
        "        r_arr_feat = torch.transpose(r_arr, -2, -1)\n",
        "        r_arr_feat = self.r_padding(r_arr_feat, pad=(4, 4))\n",
        "        r_arr_feat = self.r_arr_encoder1(r_arr_feat)\n",
        "        r_arr_feat = self.r_padding(r_arr_feat, pad=(2, 2))\n",
        "        r_arr_feat = self.r_arr_encoder2(r_arr_feat)\n",
        "\n",
        "        lc_feat = self.lc_padding(lc_arr, pad=7)\n",
        "        lc_feat = self.lc_encoder1(lc_feat)\n",
        "        lc_feat = self.lc_padding(lc_feat, pad=4)\n",
        "        lc_feat = self.lc_encoder2(lc_feat)\n",
        "\n",
        "        info_feat = self.info_encoder(lc_info)\n",
        "        info_feat = torch.squeeze(info_feat, dim=1)\n",
        "\n",
        "        rl_feat = self.rl_encoder(rl_info)\n",
        "        rl_feat = torch.squeeze(rl_feat, dim=1)\n",
        "\n",
        "        fusion_feat = torch.cat((r_arr_feat, lc_feat, info_feat, rl_feat), dim=1)\n",
        "        out = self.head(fusion_feat)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer, train_loss, es:EarlyStopping):\n",
        "    epoch_loss = 0\n",
        "    n_train = 0\n",
        "\n",
        "    model.train()\n",
        "    #with torch.autograd.detect_anomaly(True):\n",
        "    for X_train, y_train in dataloader:\n",
        "        X_train = X_train.to(device)\n",
        "        y_train = y_train.squeeze(dim=-1).type(torch.LongTensor).to(device)\n",
        "        pred_logit = model(X_train)\n",
        "\n",
        "        non_extended = torch.logical_and((X_train[:, -4] >= 0), (X_train[:, -4] < 1))\n",
        "        non_extended = torch.logical_and(non_extended, (X_train[:, -3] >= 0))\n",
        "        non_extended = torch.logical_and(non_extended, (X_train[:, -3] < 1))\n",
        "\n",
        "        loss = loss_fn(pred_logit[non_extended], y_train[non_extended])\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()*X_train.size(0)\n",
        "        n_train += X_train.size(0)\n",
        "\n",
        "    epoch_loss /= n_train\n",
        "    train_loss.append(epoch_loss)\n",
        "\n",
        "    es(epoch_loss)\n",
        "    #print(\"train_loss : {:9.4g}\".format(epoch_loss), end=' ')\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn, test_loss, epoch):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    conf_mat = np.zeros((class_num, class_num)) # confusion matrix counts (index : [y0, y_pred])\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X_test, y_test in dataloader:\n",
        "            X_test = X_test.to(device)\n",
        "            y_test = y_test.squeeze(dim=-1).type(torch.LongTensor)\n",
        "            pred_logit = model(X_test)\n",
        "            _, pred = torch.max(pred_logit, 1)\n",
        "\n",
        "            non_extended = torch.logical_and((X_test[:, -4] >= 0), (X_test[:, -4] < 1))\n",
        "            non_extended = torch.logical_and(non_extended, (X_test[:, -3] >= 0))\n",
        "            non_extended = torch.logical_and(non_extended, (X_test[:, -3] < 1)).cpu()\n",
        "            for i in range(class_num):\n",
        "                for j in range(class_num):\n",
        "                    conf_mat[i, j] += (torch.logical_and((y_test[non_extended] == i), (pred.cpu()[non_extended] == j))).sum().item()\n",
        "\n",
        "    total += np.sum(conf_mat)\n",
        "    correct += np.trace(conf_mat)\n",
        "    test_loss.append(correct/total)\n",
        "\n",
        "    print(\"train_loss : {:9.4g}\".format(train_loss[-1]), end=' ')\n",
        "    print(\"| test_score(%) : {:9.4g}\".format(100*correct/total), end=' ')\n",
        "    print(\"\\n\", end=' ')\n",
        "\n",
        "    return conf_mat\n",
        "\n",
        "# Data Processing : into classification data\n",
        "def classify_reward(data, split_ref=[-2, 2]):\n",
        "    class_num = len(split_ref)+1\n",
        "    class_idx = np.digitize(data, split_ref)\n",
        "\n",
        "    return class_idx, class_num\n",
        "\n",
        "# show training result\n",
        "def train_res_show():\n",
        "    fig = plt.figure(figsize=(14.5, 4))\n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "    ax2 = fig.add_subplot(1, 2, 2)\n",
        "\n",
        "    ax1.plot(train_loss[2:], label='train_loss', color='blue')\n",
        "    ax11 = ax1.twinx()\n",
        "    ax11.plot(test_loss[2:], label='test_score', color='orange')\n",
        "    ax1.legend()\n",
        "    ax11.legend()\n",
        "    ax1.set_title(\"Train/Test Loss (MSE)\")\n",
        "\n",
        "    conf_per = np.zeros((class_num, class_num)) #confusion matrix in percentage\n",
        "    for i in range(class_num):\n",
        "        conf_per[i, :] = 100*conf_mat[i, :]/np.sum(conf_mat[i, :])\n",
        "    im = ax2.imshow(conf_per, vmin=0, vmax=100)\n",
        "    ax2.set_title(\"Confusion Matrix\")\n",
        "    ax2.tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
        "    ax2.xaxis.set_label_position('top')\n",
        "    ax2.set_xlabel(\"Predicted Class\")\n",
        "    ax2.set_ylabel(\"Actual Class\")\n",
        "    tick = np.arange(class_num)\n",
        "    ax2.set_xticks(tick)\n",
        "    ax2.set_yticks(tick)\n",
        "    ax2.set_aspect(1)\n",
        "    plt.colorbar(im, ax=ax2, fraction=0.036, pad=0.04)\n",
        "    for i in range(class_num):\n",
        "        for j in range(class_num):\n",
        "            ax2.text(j, i, str(int(100*conf_per[i, j])/100)+\"%\", horizontalalignment='center', verticalalignment='center', color='white')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# show test image examples\n",
        "def test_img_show(i_img, test_conf):\n",
        "    fig = plt.figure(figsize=(16, 8))\n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "    ax2 = fig.add_subplot(1, 2, 2)\n",
        "\n",
        "    if i_img == 0 or True:\n",
        "        ax1.clear()\n",
        "        im1 = ax1.imshow(test_img_list[i_img], vmin=0, vmax=class_num-1)\n",
        "        ax1.set_title(\"TEST_IMAGE_\"+str(i_img))\n",
        "        plt.colorbar(im1, ax=ax1, fraction=0.026, pad=0.04)\n",
        "\n",
        "    class_map_temp = np.zeros((resol*N_set[0], resol*N_set[1]))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(N_set[0]*N_set[1]*resol*resol):\n",
        "            i = idx//int(resol*N_set[1])\n",
        "            j = idx%int(resol*N_set[1])\n",
        "            phi_action = (i/(resol*N_set[0]))%1\n",
        "            theta_action = (j/(resol*N_set[1]))%1\n",
        "\n",
        "            state = test_img_data[i_img*resol*N_set[0]*N_set[1], :906]\n",
        "            actions = np.array([phi_action, theta_action, 0.1, 0.1])\n",
        "\n",
        "            input = torch.unsqueeze(torch.tensor(np.concatenate((state, actions))).float().to(device), dim=0)\n",
        "            score = model(input)\n",
        "            class_map_temp[i, j] = np.argmax(score.cpu().numpy())\n",
        "\n",
        "    ax2.clear()\n",
        "    im2 = ax2.imshow(class_map_temp.T, vmin=0, vmax=class_num-1)\n",
        "    ax2.set_title(\"MODEL_OUTPUT_\"+str(i_img))\n",
        "    plt.colorbar(im2, ax=ax2, fraction=0.026, pad=0.04)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    extent = [int((ext_N_set[0]-N_set[0])/2), int((ext_N_set[1]-N_set[1])/2)]\n",
        "\n",
        "    for i in range(class_num):\n",
        "        for j in range(class_num):\n",
        "            test_conf[i, j] += (np.logical_and((test_img_list[i_img][extent[1]:-extent[1], extent[0]:-extent[0], 0] == i), (class_map_temp.T == j))).sum().item()\n",
        "        test_conf[i, :] = 100*test_conf[i, :]/np.sum(test_conf[i, :])\n",
        "    return test_conf\n",
        "\n",
        "def test_conf_show(test_conf):\n",
        "    fig = plt.figure(figsize=(7, 7))\n",
        "    ax1 = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "    im = ax1.imshow(test_conf, vmin=0, vmax=100)\n",
        "    ax1.set_title(\"Confusion Matrix\")\n",
        "    ax1.tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
        "    ax1.xaxis.set_label_position('top')\n",
        "    ax1.set_xlabel(\"Predicted Class\")\n",
        "    ax1.set_ylabel(\"Actual Class\")\n",
        "    tick = np.arange(class_num)\n",
        "    ax1.set_xticks(tick)\n",
        "    ax1.set_yticks(tick)\n",
        "    ax1.set_aspect(1)\n",
        "    plt.colorbar(im, ax=ax1, fraction=0.036, pad=0.04)\n",
        "    for i in range(class_num):\n",
        "        for j in range(class_num):\n",
        "            ax1.text(j, i, str(int(100*test_conf[i, j])/100)+\"%\", horizontalalignment='center', verticalalignment='center', color='white')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh0FVIe16a-f"
      },
      "outputs": [],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, x_tensor, y_tensor):\n",
        "        super(Dataset, self).__init__()\n",
        "\n",
        "        if not torch.is_tensor(x_tensor):\n",
        "            self.x = torch.tensor(x_tensor).float()\n",
        "            self.y = torch.tensor(y_tensor).float()\n",
        "        else:\n",
        "            self.x = x_tensor.float()\n",
        "            self.y = y_tensor.float()\n",
        "\n",
        "    def __getitem__(self, index): return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self): return self.x.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v_8EQeRmk4b",
        "outputId": "107cf4f2-eb84-467e-e6fa-97926721cd6d"
      },
      "outputs": [],
      "source": [
        "# seed\n",
        "seed = 722\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 1024\n",
        "learning_rate = 6e-5\n",
        "max_epoch = 1000\n",
        "\n",
        "# other parameters\n",
        "N_set = (40, 20)\n",
        "resol = 1\n",
        "\n",
        "map_modifier = RewardMapModifier(extends=(0.2, 0.2), blur_coef=(3, 2))\n",
        "chunk_size = 256\n",
        "chunk_set_size = chunk_size*N_set[0]*N_set[1]\n",
        "online_dataset_path = \"/content/gdrive/MyDrive/Asteroid RL dataset/online_dataset/\"\n",
        "\n",
        "split_ref = [-2.5, -1, 1, 2.5]\n",
        "\n",
        "\n",
        "data_len2 = int(data_RL_preset2[0, 0])\n",
        "test_img_num = 10\n",
        "test_img_idx_choice = np.random.randint(0, (data_len2-1)//800, test_img_num)\n",
        "dataset_img_idx = np.full(data_len2, False)\n",
        "for i in test_img_idx_choice:\n",
        "    dataset_img_idx[i*800+1:(i+1)*800+1] = True\n",
        "\n",
        "print(\"test_img_idx (in RL_preset_batch_2) :\", test_img_idx_choice)\n",
        "print(\"--------------------------------\")\n",
        "print(\"\")\n",
        "\n",
        "data_RL_preset = data_RL_preset0[1:, :]\n",
        "test_img_data = data_RL_preset2[dataset_img_idx, :].copy()\n",
        "del data_RL_preset2\n",
        "gc.collect()\n",
        "\n",
        "test_img_list = []\n",
        "for i in range(test_img_num):\n",
        "    test_img_list.append(test_img_data[i*resol*N_set[0]*N_set[1]:(i+1)*resol*N_set[0]*N_set[1], -1].reshape((N_set[0], N_set[1])).T)\n",
        "\n",
        "for i in range(len(test_img_list)):\n",
        "    test_img_list[i], _ = map_modifier.operation(np.expand_dims(test_img_list[i], axis=-1), None, order=['extend_vert', 'extend_hori', 'blur'])\n",
        "    test_img_list[i], _ = classify_reward(test_img_list[i], split_ref=split_ref)\n",
        "    #test_img_list[i] = test_img_list[i][:, :, 0]\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "#cut = N_set[0]*N_set[1]*2093 + 1 #1040\n",
        "#state_data = data_RL_preset[:cut, :-5]\n",
        "#action_data = data_RL_preset[:cut, -5:-1]\n",
        "#reward_data = data_RL_preset[:cut, -1:]\n",
        "state_data = data_RL_preset[:, :-5]\n",
        "action_data = data_RL_preset[:, -5:-1]\n",
        "reward_data = data_RL_preset[:, -1:]\n",
        "\n",
        "\n",
        "new_action_data = 0 * np.array([action_data[0, ...].copy()])\n",
        "new_reward_data = 0 * np.array([reward_data[0, ...].copy()])\n",
        "\n",
        "print(\"Data Shapes Before Map Modifying\")\n",
        "print(\"--------------------------------\")\n",
        "print(\"state_data  | \"+str(state_data.shape)+\", \"+str(int(1000*state_data.itemsize*state_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"action_data | \"+str(action_data.shape)+\"  , \"+str(int(1000*action_data.itemsize*action_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"reward_data | \"+str(reward_data.shape)+\"  , \"+str(int(1000*reward_data.itemsize*reward_data.size/(2**30))/1000)+\"GB\")\n",
        "\n",
        "print(\"\\n--------------------------------\")\n",
        "for i in range(math.ceil(state_data.shape[0]/chunk_set_size)):\n",
        "    if i != state_data.shape[0]//(chunk_size*N_set[0]*N_set[1]):\n",
        "        reward_map = reward_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
        "        action_maps = action_data[chunk_set_size*i:chunk_set_size*(i+1)]\n",
        "    else:\n",
        "        reward_map = reward_data[chunk_set_size*i:]\n",
        "        action_maps = action_data[chunk_set_size*i:]\n",
        "\n",
        "    print(\"Batch Shape : reward / action | \"+str(reward_map.shape)+\", \"+str(action_maps.shape)+\" --> \", end='')\n",
        "    reward_map = np.swapaxes(reward_map.reshape((-1, N_set[0], N_set[1], 1)), -2, -3)\n",
        "    action_maps = np.swapaxes(action_maps.reshape((-1, N_set[0], N_set[1], 4)), -2, -3)\n",
        "    reward_map, action_maps = map_modifier.operation(reward_map, action_maps, order=['extend_vert', 'extend_hori', 'blur'])\n",
        "    print(str(reward_map.shape)+\", \"+str(action_maps.shape))\n",
        "\n",
        "    extended_size = reward_map.shape[-2] * reward_map.shape[-3]\n",
        "    new_action_data = np.concatenate((new_action_data, action_maps.reshape(-1, 4)), axis=0)\n",
        "    new_reward_data = np.concatenate((new_reward_data, reward_map.reshape(-1, 1)), axis=0)\n",
        "print(\"--------------------------------\\n\")\n",
        "\n",
        "state_data = np.repeat(state_data[::N_set[0]*N_set[1]], repeats=extended_size, axis=0)\n",
        "action_data = np.delete(new_action_data, 0, axis=0)\n",
        "reward_data = np.delete(new_reward_data, 0, axis=0)\n",
        "\n",
        "del new_action_data, new_reward_data, reward_map, action_maps\n",
        "del data_RL_preset, data_RL_preset0\n",
        "gc.collect()\n",
        "\n",
        "print(\"Data Shapes After Map Mpdifying\")\n",
        "print(\"--------------------------------\")\n",
        "print(\"state_data  | \"+str(state_data.shape)+\", \"+str(int(1000*state_data.itemsize*state_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"action_data | \"+str(action_data.shape)+\"  , \"+str(int(1000*action_data.itemsize*action_data.size/(2**30))/1000)+\"GB\")\n",
        "print(\"reward_data | \"+str(reward_data.shape)+\"  , \"+str(int(1000*reward_data.itemsize*reward_data.size/(2**30))/1000)+\"GB\")\n",
        "\n",
        "ext_N_set = map_modifier.ext_N_set(N_set)\n",
        "\n",
        "\n",
        "total_data = np.concatenate((state_data, action_data, reward_data), axis=1)\n",
        "state_shape = state_data.shape[1]\n",
        "del state_data, action_data, reward_data\n",
        "gc.collect()\n",
        "\n",
        "train_data, test_data = data_split(total_data, train_ratio=0.85, shuffle=True, copy=True)\n",
        "del total_data\n",
        "gc.collect()\n",
        "\n",
        "train_state_data = train_data[:, :state_shape].copy()\n",
        "train_action_data = train_data[:, state_shape:state_shape+4].copy()\n",
        "train_reward_data = train_data[:, -1].reshape(-1, 1)\n",
        "del train_data\n",
        "gc.collect()\n",
        "\n",
        "test_state_data = test_data[:, :state_shape].copy()\n",
        "test_action_data = test_data[:, state_shape:state_shape+4].copy()\n",
        "test_reward_data = test_data[:, -1].reshape(-1, 1)\n",
        "del test_data\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "train_reward_data, class_num = classify_reward(train_reward_data, split_ref=split_ref)\n",
        "test_reward_data, class_num = classify_reward(test_reward_data, split_ref=split_ref)\n",
        "train_reward_data = train_reward_data.astype(np.float32)\n",
        "test_reward_data = test_reward_data.astype(np.float32)\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_P3IAswivzd"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(np.concatenate((train_state_data, train_action_data), axis=1), train_reward_data)\n",
        "del train_state_data, train_action_data, train_reward_data\n",
        "gc.collect()\n",
        "\n",
        "test_dataset = Dataset(np.concatenate((test_state_data, test_action_data), axis=1), test_reward_data)\n",
        "del test_state_data, test_action_data, test_reward_data\n",
        "gc.collect()\n",
        "\n",
        "train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2rI3haGDmfak",
        "outputId": "b5e59603-22be-4b43-d62b-8fb3d8690a62"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "learning_rate = 8e-5\n",
        "max_epoch = 300\n",
        "\n",
        "model = QValueClassifierNet_CNN(input_dim=910, hidden_dim=1024, output_dim=class_num, activation=nn.ELU, dropout=0.15).to(device)\n",
        "summary(model, (1, model.input_dim))\n",
        "\n",
        "class_weight = 60*torch.ones(class_num)\n",
        "class_weight[class_weight.shape[0]//2] = 30\n",
        "class_weight[class_weight.shape[0]//2 + 1:] = 100\n",
        "class_weight = class_weight.float().to(device)\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weight)\n",
        "\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "es = EarlyStopping(patience=2000, delta=0.1)\n",
        "for epoch in tqdm(range(max_epoch)):\n",
        "    #print(\"EPOCH \"+str(epoch)+\" TRAINING...\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer, train_loss, es)\n",
        "    #print(\"EPOCH \"+str(epoch)+\" TESTING...\")\n",
        "    conf_mat = test_loop(test_dataloader, model, loss_fn, test_loss, epoch)\n",
        "    #print(\"\")\n",
        "\n",
        "    if es.early_stop:\n",
        "        print(\"EarlyStop Triggered : Bestscore = {:7.4g}\".format(es.best_score))\n",
        "        break\n",
        "\n",
        "    if (epoch+1)%10 == 0 and epoch != 0:\n",
        "        #plt.plot(train_loss[2:], label='train_loss')\n",
        "        #plt.plot(test_loss[2:], label='test_score')\n",
        "        #plt.legend()\n",
        "        #plt.title(\"Train/Test Loss (MSE)\")\n",
        "        #plt.show()\n",
        "        train_res_show()\n",
        "\n",
        "        test_conf = np.zeros((class_num, class_num))\n",
        "        for i in range(test_img_num):\n",
        "            test_conf = test_img_show(i, test_conf)\n",
        "        test_conf_show(test_conf)\n",
        "\n",
        "    print(\"[epochs:{:2}]\".format(epoch+2), end='')\n",
        "\n",
        "print(\"DONE\")\n",
        "\n",
        "plt.plot(train_loss[2:], label='train_loss')\n",
        "plt.plot(test_loss[2:], label='test_loss')\n",
        "plt.legend()\n",
        "plt.title(\"Train/Test Loss (MSE)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HszKth5wB_Kr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7k7TzbP0b0hm",
        "i3luOZYEcBDo",
        "HBqbzM47LGZE",
        "qyACgjD5P-ml"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
